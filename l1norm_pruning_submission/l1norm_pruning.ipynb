{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jylyo23Y339Q",
        "outputId": "7c3c50e3-093d-4fdf-d481-6cc50dae58dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_images.pkl\n",
            "train_labels.pkl\n",
            "val_images.pkl\n",
            "val_labels.pkl\n"
          ]
        }
      ],
      "source": [
        "# untar\n",
        "!tar -xvzf dataset.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dgQu7yn3Vdq",
        "outputId": "6b389192-8c9f-49b1-b859-d3226b38465a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e3OrcZ3t3Vdr"
      },
      "outputs": [],
      "source": [
        "# load train\n",
        "train_images = pickle.load(open(\"../train_images.pkl\", \"rb\"))\n",
        "train_labels = pickle.load(open(\"../train_labels.pkl\", \"rb\"))\n",
        "\n",
        "# load val\n",
        "val_images = pickle.load(open(\"../val_images.pkl\", \"rb\"))\n",
        "val_labels = pickle.load(open(\"../val_labels.pkl\", \"rb\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_V1jePpk3Vdr"
      },
      "outputs": [],
      "source": [
        "def measure_sparsity(weights):\n",
        "    num_zeros = 0\n",
        "    num_nonzeros = 0\n",
        "    for weight in weights:\n",
        "        z = tf.math.count_nonzero(tf.equal(weight, 0)).numpy()\n",
        "        nz = tf.size(weight).numpy() - z\n",
        "        num_zeros += z\n",
        "        num_nonzeros += nz\n",
        "\n",
        "    return num_zeros / (num_zeros + num_nonzeros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "02Iz_fBJ6wBM"
      },
      "outputs": [],
      "source": [
        "def calc_std(weights):\n",
        "    tmp = []\n",
        "    for w in weights:\n",
        "        tmp.append(w.numpy().flatten())\n",
        "    oned_stackedweights = np.hstack(tmp)\n",
        "    return np.std(oned_stackedweights)\n",
        "\n",
        "\n",
        "def prune(weights, stdval, factor=1):\n",
        "    pruned_weights = deepcopy(weights)\n",
        "    threshold = stdval * factor\n",
        "    for i, w in enumerate(pruned_weights):\n",
        "        mask = tf.cast(tf.greater(\n",
        "            tf.abs(w), threshold), tf.float32)\n",
        "        pruned_weights[i] = (tf.multiply(w, mask))\n",
        "    return pruned_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lzUdcJWv3Vdr"
      },
      "outputs": [],
      "source": [
        "def prune(model, factor=0.5, dense_thresh=None):\n",
        "    pruned_weights = []\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        if isinstance(layer, Conv2D):\n",
        "            weights, biases = layer.get_weights()\n",
        "            w = deepcopy(weights)\n",
        "            b = deepcopy(biases)\n",
        "        \n",
        "            l1_norms = np.sum(np.abs(w), axis=(0, 1, 2))\n",
        "            l1_norms_sorted_indices = np.argsort(l1_norms)[::-1]\n",
        "            tot = len(l1_norms_sorted_indices)\n",
        "            cutoff = round(factor * tot)\n",
        "            w[:, :, :, l1_norms_sorted_indices[-cutoff:]] = 0.0\n",
        "            b[l1_norms_sorted_indices[-cutoff:]] = 0\n",
        "\n",
        "            pruned_weights.append(w)\n",
        "            pruned_weights.append(b)\n",
        "        \n",
        "        elif isinstance(layer, Dense):\n",
        "            weights, biases = layer.get_weights()\n",
        "            w = deepcopy(weights)\n",
        "            b = deepcopy(biases)\n",
        "\n",
        "            if dense_thresh is not None:\n",
        "                mask = tf.cast(tf.greater(\n",
        "                    tf.abs(w), dense_thresh), tf.float32)\n",
        "                w = tf.multiply(w, mask)\n",
        "\n",
        "            pruned_weights.append(w)\n",
        "            pruned_weights.append(b)\n",
        "\n",
        "    return pruned_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRKfx_hU3Vdr",
        "outputId": "bc2fc65a-c64d-48e8-e3ca-2db6d37ede14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.5941 - accuracy: 0.2493\n",
            "Epoch 1: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 13s 12ms/step - loss: 1.5941 - accuracy: 0.2493 - val_loss: 1.5657 - val_accuracy: 0.2737\n",
            "Epoch 2/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.5531 - accuracy: 0.2996\n",
            "Epoch 2: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.5530 - accuracy: 0.3000 - val_loss: 1.5302 - val_accuracy: 0.3164\n",
            "Epoch 3/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.5283 - accuracy: 0.3212\n",
            "Epoch 3: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.5280 - accuracy: 0.3213 - val_loss: 1.4998 - val_accuracy: 0.3438\n",
            "Epoch 4/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.4971 - accuracy: 0.3470\n",
            "Epoch 4: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.4964 - accuracy: 0.3475 - val_loss: 1.4614 - val_accuracy: 0.3604\n",
            "Epoch 5/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.4565 - accuracy: 0.3659\n",
            "Epoch 5: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.4559 - accuracy: 0.3662 - val_loss: 1.4148 - val_accuracy: 0.3913\n",
            "Epoch 6/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.4221 - accuracy: 0.3825\n",
            "Epoch 6: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.4218 - accuracy: 0.3827 - val_loss: 1.3792 - val_accuracy: 0.4087\n",
            "Epoch 7/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.3912 - accuracy: 0.3992\n",
            "Epoch 7: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.3911 - accuracy: 0.3987 - val_loss: 1.3525 - val_accuracy: 0.4143\n",
            "Epoch 8/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.3744 - accuracy: 0.4074\n",
            "Epoch 8: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.3742 - accuracy: 0.4072 - val_loss: 1.3322 - val_accuracy: 0.4368\n",
            "Epoch 9/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.3601 - accuracy: 0.4171\n",
            "Epoch 9: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.3599 - accuracy: 0.4174 - val_loss: 1.3245 - val_accuracy: 0.4222\n",
            "Epoch 10/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.3346 - accuracy: 0.4308\n",
            "Epoch 10: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.3346 - accuracy: 0.4307 - val_loss: 1.2927 - val_accuracy: 0.4598\n",
            "Epoch 11/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.3276 - accuracy: 0.4367\n",
            "Epoch 11: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.3277 - accuracy: 0.4368 - val_loss: 1.2893 - val_accuracy: 0.4539\n",
            "Epoch 12/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.3054 - accuracy: 0.4538\n",
            "Epoch 12: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.3059 - accuracy: 0.4534 - val_loss: 1.2603 - val_accuracy: 0.4630\n",
            "Epoch 13/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.2974 - accuracy: 0.4528\n",
            "Epoch 13: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2977 - accuracy: 0.4527 - val_loss: 1.2482 - val_accuracy: 0.4855\n",
            "Epoch 14/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.2810 - accuracy: 0.4639\n",
            "Epoch 14: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2804 - accuracy: 0.4642 - val_loss: 1.2415 - val_accuracy: 0.4812\n",
            "Epoch 15/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.2656 - accuracy: 0.4718\n",
            "Epoch 15: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2656 - accuracy: 0.4718 - val_loss: 1.2204 - val_accuracy: 0.4990\n",
            "Epoch 16/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.2542 - accuracy: 0.4800\n",
            "Epoch 16: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2542 - accuracy: 0.4800 - val_loss: 1.2157 - val_accuracy: 0.4954\n",
            "Epoch 17/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.2465 - accuracy: 0.4828\n",
            "Epoch 17: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2466 - accuracy: 0.4824 - val_loss: 1.2146 - val_accuracy: 0.5038\n",
            "Epoch 18/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.2337 - accuracy: 0.4928\n",
            "Epoch 18: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2334 - accuracy: 0.4928 - val_loss: 1.2023 - val_accuracy: 0.4994\n",
            "Epoch 19/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.2216 - accuracy: 0.4983\n",
            "Epoch 19: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2215 - accuracy: 0.4983 - val_loss: 1.1822 - val_accuracy: 0.5172\n",
            "Epoch 20/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.2147 - accuracy: 0.5048\n",
            "Epoch 20: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2136 - accuracy: 0.5051 - val_loss: 1.1751 - val_accuracy: 0.5208\n",
            "Epoch 21/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.2086 - accuracy: 0.5037\n",
            "Epoch 21: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2086 - accuracy: 0.5037 - val_loss: 1.1706 - val_accuracy: 0.5259\n",
            "Epoch 22/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.2000 - accuracy: 0.5130\n",
            "Epoch 22: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2000 - accuracy: 0.5131 - val_loss: 1.1626 - val_accuracy: 0.5216\n",
            "Epoch 23/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.1877 - accuracy: 0.5163\n",
            "Epoch 23: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1881 - accuracy: 0.5161 - val_loss: 1.1512 - val_accuracy: 0.5319\n",
            "Epoch 24/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.1841 - accuracy: 0.5205\n",
            "Epoch 24: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1841 - accuracy: 0.5205 - val_loss: 1.1427 - val_accuracy: 0.5331\n",
            "Epoch 25/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.1751 - accuracy: 0.5244\n",
            "Epoch 25: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1751 - accuracy: 0.5246 - val_loss: 1.1412 - val_accuracy: 0.5303\n",
            "Epoch 26/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.1654 - accuracy: 0.5271\n",
            "Epoch 26: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1653 - accuracy: 0.5273 - val_loss: 1.1314 - val_accuracy: 0.5386\n",
            "Epoch 27/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1586 - accuracy: 0.5279\n",
            "Epoch 27: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1590 - accuracy: 0.5279 - val_loss: 1.1311 - val_accuracy: 0.5287\n",
            "Epoch 28/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.1473 - accuracy: 0.5342\n",
            "Epoch 28: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1473 - accuracy: 0.5342 - val_loss: 1.1260 - val_accuracy: 0.5390\n",
            "Epoch 29/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1446 - accuracy: 0.5379\n",
            "Epoch 29: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1435 - accuracy: 0.5382 - val_loss: 1.1142 - val_accuracy: 0.5529\n",
            "Epoch 30/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1408 - accuracy: 0.5370\n",
            "Epoch 30: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1404 - accuracy: 0.5374 - val_loss: 1.1063 - val_accuracy: 0.5493\n",
            "Epoch 31/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.1320 - accuracy: 0.5412\n",
            "Epoch 31: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1325 - accuracy: 0.5412 - val_loss: 1.1041 - val_accuracy: 0.5501\n",
            "Epoch 32/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.1222 - accuracy: 0.5483\n",
            "Epoch 32: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1220 - accuracy: 0.5486 - val_loss: 1.1089 - val_accuracy: 0.5501\n",
            "Epoch 33/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1194 - accuracy: 0.5488\n",
            "Epoch 33: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1197 - accuracy: 0.5493 - val_loss: 1.0874 - val_accuracy: 0.5604\n",
            "Epoch 34/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.1175 - accuracy: 0.5491\n",
            "Epoch 34: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1173 - accuracy: 0.5491 - val_loss: 1.1005 - val_accuracy: 0.5529\n",
            "Epoch 35/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.1079 - accuracy: 0.5565\n",
            "Epoch 35: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1080 - accuracy: 0.5564 - val_loss: 1.0770 - val_accuracy: 0.5679\n",
            "Epoch 36/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.1014 - accuracy: 0.5572\n",
            "Epoch 36: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1013 - accuracy: 0.5575 - val_loss: 1.0729 - val_accuracy: 0.5651\n",
            "Epoch 37/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.0933 - accuracy: 0.5608\n",
            "Epoch 37: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0933 - accuracy: 0.5608 - val_loss: 1.0676 - val_accuracy: 0.5651\n",
            "Epoch 38/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0906 - accuracy: 0.5620\n",
            "Epoch 38: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0902 - accuracy: 0.5621 - val_loss: 1.0624 - val_accuracy: 0.5691\n",
            "Epoch 39/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0851 - accuracy: 0.5647\n",
            "Epoch 39: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0853 - accuracy: 0.5646 - val_loss: 1.0644 - val_accuracy: 0.5675\n",
            "Epoch 40/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0818 - accuracy: 0.5679\n",
            "Epoch 40: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0818 - accuracy: 0.5681 - val_loss: 1.0647 - val_accuracy: 0.5739\n",
            "Epoch 41/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0750 - accuracy: 0.5722\n",
            "Epoch 41: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0755 - accuracy: 0.5717 - val_loss: 1.0527 - val_accuracy: 0.5798\n",
            "Epoch 42/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0693 - accuracy: 0.5714\n",
            "Epoch 42: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0704 - accuracy: 0.5717 - val_loss: 1.0431 - val_accuracy: 0.5830\n",
            "Epoch 43/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0621 - accuracy: 0.5811\n",
            "Epoch 43: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0627 - accuracy: 0.5808 - val_loss: 1.0393 - val_accuracy: 0.5865\n",
            "Epoch 44/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0671 - accuracy: 0.5749\n",
            "Epoch 44: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0664 - accuracy: 0.5759 - val_loss: 1.0336 - val_accuracy: 0.5869\n",
            "Epoch 45/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0571 - accuracy: 0.5784\n",
            "Epoch 45: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0569 - accuracy: 0.5786 - val_loss: 1.0375 - val_accuracy: 0.5822\n",
            "Epoch 46/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0550 - accuracy: 0.5791\n",
            "Epoch 46: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0548 - accuracy: 0.5789 - val_loss: 1.0320 - val_accuracy: 0.5877\n",
            "Epoch 47/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0498 - accuracy: 0.5833\n",
            "Epoch 47: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0503 - accuracy: 0.5831 - val_loss: 1.0198 - val_accuracy: 0.5929\n",
            "Epoch 48/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0426 - accuracy: 0.5866\n",
            "Epoch 48: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0432 - accuracy: 0.5861 - val_loss: 1.0157 - val_accuracy: 0.5921\n",
            "Epoch 49/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0447 - accuracy: 0.5855\n",
            "Epoch 49: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0443 - accuracy: 0.5858 - val_loss: 1.0227 - val_accuracy: 0.5877\n",
            "Epoch 50/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0346 - accuracy: 0.5905\n",
            "Epoch 50: saving model to l1norm_pruning_itr_0.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0340 - accuracy: 0.5903 - val_loss: 1.0161 - val_accuracy: 0.5893\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 1.0161 - accuracy: 0.5893\n",
            "Sparsity: 0.0018265132822764124 | val loss: 1.016096830368042 | val acc: 0.5893069505691528\n",
            "Epoch 1/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.4838 - accuracy: 0.3401\n",
            "Epoch 1: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.4817 - accuracy: 0.3417 - val_loss: 1.3419 - val_accuracy: 0.4448\n",
            "Epoch 2/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.3253 - accuracy: 0.4440\n",
            "Epoch 2: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.3254 - accuracy: 0.4440 - val_loss: 1.2539 - val_accuracy: 0.4863\n",
            "Epoch 3/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.2716 - accuracy: 0.4731\n",
            "Epoch 3: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2723 - accuracy: 0.4730 - val_loss: 1.2319 - val_accuracy: 0.4859\n",
            "Epoch 4/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.2477 - accuracy: 0.4856\n",
            "Epoch 4: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2478 - accuracy: 0.4854 - val_loss: 1.2022 - val_accuracy: 0.5050\n",
            "Epoch 5/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.2303 - accuracy: 0.4954\n",
            "Epoch 5: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2299 - accuracy: 0.4955 - val_loss: 1.1965 - val_accuracy: 0.4998\n",
            "Epoch 6/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.2148 - accuracy: 0.5072\n",
            "Epoch 6: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2148 - accuracy: 0.5071 - val_loss: 1.1861 - val_accuracy: 0.5089\n",
            "Epoch 7/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.2073 - accuracy: 0.5084\n",
            "Epoch 7: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2068 - accuracy: 0.5087 - val_loss: 1.1719 - val_accuracy: 0.5149\n",
            "Epoch 8/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.1932 - accuracy: 0.5175\n",
            "Epoch 8: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1934 - accuracy: 0.5176 - val_loss: 1.1551 - val_accuracy: 0.5224\n",
            "Epoch 9/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.1871 - accuracy: 0.5179\n",
            "Epoch 9: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1889 - accuracy: 0.5172 - val_loss: 1.1513 - val_accuracy: 0.5248\n",
            "Epoch 10/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.1774 - accuracy: 0.5236\n",
            "Epoch 10: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1780 - accuracy: 0.5234 - val_loss: 1.1301 - val_accuracy: 0.5358\n",
            "Epoch 11/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.1714 - accuracy: 0.5271\n",
            "Epoch 11: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1703 - accuracy: 0.5276 - val_loss: 1.1376 - val_accuracy: 0.5323\n",
            "Epoch 12/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.1634 - accuracy: 0.5335\n",
            "Epoch 12: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1632 - accuracy: 0.5335 - val_loss: 1.1299 - val_accuracy: 0.5327\n",
            "Epoch 13/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.1509 - accuracy: 0.5371\n",
            "Epoch 13: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1501 - accuracy: 0.5370 - val_loss: 1.1179 - val_accuracy: 0.5370\n",
            "Epoch 14/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.1469 - accuracy: 0.5396\n",
            "Epoch 14: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1471 - accuracy: 0.5395 - val_loss: 1.1183 - val_accuracy: 0.5465\n",
            "Epoch 15/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1410 - accuracy: 0.5408\n",
            "Epoch 15: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1398 - accuracy: 0.5407 - val_loss: 1.1096 - val_accuracy: 0.5489\n",
            "Epoch 16/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.1363 - accuracy: 0.5431\n",
            "Epoch 16: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1373 - accuracy: 0.5429 - val_loss: 1.0925 - val_accuracy: 0.5572\n",
            "Epoch 17/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.1257 - accuracy: 0.5490\n",
            "Epoch 17: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1256 - accuracy: 0.5491 - val_loss: 1.0920 - val_accuracy: 0.5493\n",
            "Epoch 18/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1213 - accuracy: 0.5511\n",
            "Epoch 18: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1218 - accuracy: 0.5514 - val_loss: 1.0823 - val_accuracy: 0.5719\n",
            "Epoch 19/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.1196 - accuracy: 0.5552\n",
            "Epoch 19: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1198 - accuracy: 0.5549 - val_loss: 1.0752 - val_accuracy: 0.5707\n",
            "Epoch 20/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.1118 - accuracy: 0.5566\n",
            "Epoch 20: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1120 - accuracy: 0.5562 - val_loss: 1.0735 - val_accuracy: 0.5747\n",
            "Epoch 21/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0977 - accuracy: 0.5647\n",
            "Epoch 21: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0984 - accuracy: 0.5646 - val_loss: 1.0667 - val_accuracy: 0.5683\n",
            "Epoch 22/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0973 - accuracy: 0.5667\n",
            "Epoch 22: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0982 - accuracy: 0.5664 - val_loss: 1.0638 - val_accuracy: 0.5735\n",
            "Epoch 23/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0952 - accuracy: 0.5654\n",
            "Epoch 23: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0954 - accuracy: 0.5653 - val_loss: 1.0806 - val_accuracy: 0.5640\n",
            "Epoch 24/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0878 - accuracy: 0.5637\n",
            "Epoch 24: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0876 - accuracy: 0.5648 - val_loss: 1.0658 - val_accuracy: 0.5723\n",
            "Epoch 25/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0876 - accuracy: 0.5669\n",
            "Epoch 25: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0866 - accuracy: 0.5673 - val_loss: 1.0507 - val_accuracy: 0.5750\n",
            "Epoch 26/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0759 - accuracy: 0.5739\n",
            "Epoch 26: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0757 - accuracy: 0.5733 - val_loss: 1.0560 - val_accuracy: 0.5723\n",
            "Epoch 27/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0757 - accuracy: 0.5722\n",
            "Epoch 27: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0759 - accuracy: 0.5725 - val_loss: 1.0516 - val_accuracy: 0.5711\n",
            "Epoch 28/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0670 - accuracy: 0.5786\n",
            "Epoch 28: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0656 - accuracy: 0.5794 - val_loss: 1.0410 - val_accuracy: 0.5794\n",
            "Epoch 29/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0581 - accuracy: 0.5846\n",
            "Epoch 29: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0579 - accuracy: 0.5846 - val_loss: 1.0357 - val_accuracy: 0.5810\n",
            "Epoch 30/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0542 - accuracy: 0.5842\n",
            "Epoch 30: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0537 - accuracy: 0.5848 - val_loss: 1.0223 - val_accuracy: 0.5933\n",
            "Epoch 31/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0541 - accuracy: 0.5837\n",
            "Epoch 31: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0540 - accuracy: 0.5834 - val_loss: 1.0222 - val_accuracy: 0.5909\n",
            "Epoch 32/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0455 - accuracy: 0.5887\n",
            "Epoch 32: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0457 - accuracy: 0.5884 - val_loss: 1.0344 - val_accuracy: 0.5814\n",
            "Epoch 33/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0447 - accuracy: 0.5873\n",
            "Epoch 33: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0448 - accuracy: 0.5875 - val_loss: 1.0158 - val_accuracy: 0.5976\n",
            "Epoch 34/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0402 - accuracy: 0.5873\n",
            "Epoch 34: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0395 - accuracy: 0.5879 - val_loss: 1.0119 - val_accuracy: 0.5972\n",
            "Epoch 35/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0347 - accuracy: 0.5953\n",
            "Epoch 35: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0345 - accuracy: 0.5955 - val_loss: 1.0190 - val_accuracy: 0.5972\n",
            "Epoch 36/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0326 - accuracy: 0.5982\n",
            "Epoch 36: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0323 - accuracy: 0.5987 - val_loss: 1.0255 - val_accuracy: 0.5822\n",
            "Epoch 37/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0293 - accuracy: 0.5943\n",
            "Epoch 37: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0293 - accuracy: 0.5944 - val_loss: 1.0019 - val_accuracy: 0.6048\n",
            "Epoch 38/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0283 - accuracy: 0.5954\n",
            "Epoch 38: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0283 - accuracy: 0.5954 - val_loss: 1.0074 - val_accuracy: 0.5964\n",
            "Epoch 39/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.0199 - accuracy: 0.5985\n",
            "Epoch 39: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0199 - accuracy: 0.5985 - val_loss: 1.0026 - val_accuracy: 0.6028\n",
            "Epoch 40/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0135 - accuracy: 0.6010\n",
            "Epoch 40: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0145 - accuracy: 0.6000 - val_loss: 1.0053 - val_accuracy: 0.5937\n",
            "Epoch 41/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0170 - accuracy: 0.6008\n",
            "Epoch 41: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0169 - accuracy: 0.6009 - val_loss: 0.9970 - val_accuracy: 0.5949\n",
            "Epoch 42/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0108 - accuracy: 0.6043\n",
            "Epoch 42: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0108 - accuracy: 0.6043 - val_loss: 0.9816 - val_accuracy: 0.6139\n",
            "Epoch 43/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0110 - accuracy: 0.6070\n",
            "Epoch 43: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0105 - accuracy: 0.6071 - val_loss: 0.9818 - val_accuracy: 0.6103\n",
            "Epoch 44/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0061 - accuracy: 0.6069\n",
            "Epoch 44: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0093 - accuracy: 0.6051 - val_loss: 0.9804 - val_accuracy: 0.6091\n",
            "Epoch 45/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9953 - accuracy: 0.6121\n",
            "Epoch 45: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9955 - accuracy: 0.6119 - val_loss: 0.9759 - val_accuracy: 0.6079\n",
            "Epoch 46/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9965 - accuracy: 0.6110\n",
            "Epoch 46: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9962 - accuracy: 0.6108 - val_loss: 0.9735 - val_accuracy: 0.6190\n",
            "Epoch 47/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9907 - accuracy: 0.6106\n",
            "Epoch 47: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9909 - accuracy: 0.6105 - val_loss: 0.9734 - val_accuracy: 0.6091\n",
            "Epoch 48/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9972 - accuracy: 0.6080\n",
            "Epoch 48: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9962 - accuracy: 0.6088 - val_loss: 0.9645 - val_accuracy: 0.6123\n",
            "Epoch 49/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9822 - accuracy: 0.6151\n",
            "Epoch 49: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9816 - accuracy: 0.6153 - val_loss: 0.9702 - val_accuracy: 0.6131\n",
            "Epoch 50/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9810 - accuracy: 0.6172\n",
            "Epoch 50: saving model to l1norm_pruning_itr_1.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9811 - accuracy: 0.6176 - val_loss: 0.9844 - val_accuracy: 0.6063\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.9844 - accuracy: 0.6063\n",
            "Sparsity: 0.3639568045630788 | val loss: 0.9844444394111633 | val acc: 0.6063366532325745\n",
            "Epoch 1/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.4622 - accuracy: 0.3688\n",
            "Epoch 1: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.4601 - accuracy: 0.3703 - val_loss: 1.2905 - val_accuracy: 0.4697\n",
            "Epoch 2/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.2811 - accuracy: 0.4720\n",
            "Epoch 2: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2805 - accuracy: 0.4727 - val_loss: 1.2353 - val_accuracy: 0.4986\n",
            "Epoch 3/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.2306 - accuracy: 0.4982\n",
            "Epoch 3: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2304 - accuracy: 0.4982 - val_loss: 1.1792 - val_accuracy: 0.5248\n",
            "Epoch 4/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.2098 - accuracy: 0.5094\n",
            "Epoch 4: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2096 - accuracy: 0.5095 - val_loss: 1.1535 - val_accuracy: 0.5343\n",
            "Epoch 5/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1915 - accuracy: 0.5169\n",
            "Epoch 5: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1909 - accuracy: 0.5174 - val_loss: 1.1424 - val_accuracy: 0.5331\n",
            "Epoch 6/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.1780 - accuracy: 0.5254\n",
            "Epoch 6: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1777 - accuracy: 0.5255 - val_loss: 1.1342 - val_accuracy: 0.5394\n",
            "Epoch 7/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.1643 - accuracy: 0.5327\n",
            "Epoch 7: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1647 - accuracy: 0.5327 - val_loss: 1.1195 - val_accuracy: 0.5481\n",
            "Epoch 8/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.1525 - accuracy: 0.5360\n",
            "Epoch 8: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1522 - accuracy: 0.5361 - val_loss: 1.1224 - val_accuracy: 0.5442\n",
            "Epoch 9/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1465 - accuracy: 0.5406\n",
            "Epoch 9: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1480 - accuracy: 0.5399 - val_loss: 1.1123 - val_accuracy: 0.5497\n",
            "Epoch 10/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1423 - accuracy: 0.5427\n",
            "Epoch 10: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1418 - accuracy: 0.5430 - val_loss: 1.0931 - val_accuracy: 0.5608\n",
            "Epoch 11/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.1321 - accuracy: 0.5491\n",
            "Epoch 11: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1313 - accuracy: 0.5497 - val_loss: 1.0835 - val_accuracy: 0.5644\n",
            "Epoch 12/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.1234 - accuracy: 0.5541\n",
            "Epoch 12: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1234 - accuracy: 0.5539 - val_loss: 1.0761 - val_accuracy: 0.5683\n",
            "Epoch 13/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1157 - accuracy: 0.5550\n",
            "Epoch 13: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1145 - accuracy: 0.5551 - val_loss: 1.0716 - val_accuracy: 0.5715\n",
            "Epoch 14/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.1073 - accuracy: 0.5585\n",
            "Epoch 14: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1073 - accuracy: 0.5585 - val_loss: 1.0671 - val_accuracy: 0.5644\n",
            "Epoch 15/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.1042 - accuracy: 0.5626\n",
            "Epoch 15: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1041 - accuracy: 0.5626 - val_loss: 1.0600 - val_accuracy: 0.5731\n",
            "Epoch 16/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.0987 - accuracy: 0.5646\n",
            "Epoch 16: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0987 - accuracy: 0.5646 - val_loss: 1.0681 - val_accuracy: 0.5663\n",
            "Epoch 17/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.0912 - accuracy: 0.5699\n",
            "Epoch 17: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 11ms/step - loss: 1.0912 - accuracy: 0.5699 - val_loss: 1.0563 - val_accuracy: 0.5715\n",
            "Epoch 18/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0899 - accuracy: 0.5643\n",
            "Epoch 18: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0894 - accuracy: 0.5650 - val_loss: 1.0724 - val_accuracy: 0.5596\n",
            "Epoch 19/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0826 - accuracy: 0.5706\n",
            "Epoch 19: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0823 - accuracy: 0.5710 - val_loss: 1.0521 - val_accuracy: 0.5762\n",
            "Epoch 20/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0773 - accuracy: 0.5743\n",
            "Epoch 20: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0768 - accuracy: 0.5742 - val_loss: 1.0288 - val_accuracy: 0.5917\n",
            "Epoch 21/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0716 - accuracy: 0.5716\n",
            "Epoch 21: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0704 - accuracy: 0.5730 - val_loss: 1.0331 - val_accuracy: 0.5822\n",
            "Epoch 22/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0681 - accuracy: 0.5768\n",
            "Epoch 22: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0687 - accuracy: 0.5767 - val_loss: 1.0275 - val_accuracy: 0.5846\n",
            "Epoch 23/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0626 - accuracy: 0.5825\n",
            "Epoch 23: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0629 - accuracy: 0.5825 - val_loss: 1.0199 - val_accuracy: 0.5897\n",
            "Epoch 24/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0567 - accuracy: 0.5854\n",
            "Epoch 24: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0571 - accuracy: 0.5854 - val_loss: 1.0139 - val_accuracy: 0.5921\n",
            "Epoch 25/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.0534 - accuracy: 0.5851\n",
            "Epoch 25: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0534 - accuracy: 0.5851 - val_loss: 1.0172 - val_accuracy: 0.5897\n",
            "Epoch 26/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0468 - accuracy: 0.5876\n",
            "Epoch 26: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0479 - accuracy: 0.5873 - val_loss: 1.0204 - val_accuracy: 0.5901\n",
            "Epoch 27/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0401 - accuracy: 0.5893\n",
            "Epoch 27: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 10ms/step - loss: 1.0405 - accuracy: 0.5891 - val_loss: 1.0081 - val_accuracy: 0.5937\n",
            "Epoch 28/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0370 - accuracy: 0.5901\n",
            "Epoch 28: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0371 - accuracy: 0.5900 - val_loss: 1.0080 - val_accuracy: 0.5925\n",
            "Epoch 29/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0352 - accuracy: 0.5910\n",
            "Epoch 29: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0345 - accuracy: 0.5912 - val_loss: 1.0164 - val_accuracy: 0.5901\n",
            "Epoch 30/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.0335 - accuracy: 0.5956\n",
            "Epoch 30: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0335 - accuracy: 0.5956 - val_loss: 0.9942 - val_accuracy: 0.6051\n",
            "Epoch 31/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0250 - accuracy: 0.5993\n",
            "Epoch 31: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0254 - accuracy: 0.5990 - val_loss: 1.0105 - val_accuracy: 0.5921\n",
            "Epoch 32/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0221 - accuracy: 0.6012\n",
            "Epoch 32: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0218 - accuracy: 0.6011 - val_loss: 0.9951 - val_accuracy: 0.5992\n",
            "Epoch 33/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0200 - accuracy: 0.5959\n",
            "Epoch 33: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 10ms/step - loss: 1.0202 - accuracy: 0.5958 - val_loss: 0.9879 - val_accuracy: 0.6012\n",
            "Epoch 34/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0150 - accuracy: 0.6003\n",
            "Epoch 34: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0150 - accuracy: 0.6006 - val_loss: 1.0078 - val_accuracy: 0.5956\n",
            "Epoch 35/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0249 - accuracy: 0.6003\n",
            "Epoch 35: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0251 - accuracy: 0.6003 - val_loss: 0.9825 - val_accuracy: 0.6127\n",
            "Epoch 36/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0096 - accuracy: 0.6021\n",
            "Epoch 36: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0100 - accuracy: 0.6013 - val_loss: 0.9826 - val_accuracy: 0.6040\n",
            "Epoch 37/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0068 - accuracy: 0.6071\n",
            "Epoch 37: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0085 - accuracy: 0.6062 - val_loss: 0.9958 - val_accuracy: 0.6012\n",
            "Epoch 38/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0063 - accuracy: 0.6044\n",
            "Epoch 38: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0055 - accuracy: 0.6045 - val_loss: 0.9768 - val_accuracy: 0.6079\n",
            "Epoch 39/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0051 - accuracy: 0.6036\n",
            "Epoch 39: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0055 - accuracy: 0.6032 - val_loss: 0.9725 - val_accuracy: 0.6111\n",
            "Epoch 40/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.0007 - accuracy: 0.6088\n",
            "Epoch 40: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0007 - accuracy: 0.6088 - val_loss: 0.9789 - val_accuracy: 0.6091\n",
            "Epoch 41/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9958 - accuracy: 0.6142\n",
            "Epoch 41: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9970 - accuracy: 0.6135 - val_loss: 0.9668 - val_accuracy: 0.6103\n",
            "Epoch 42/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9903 - accuracy: 0.6167\n",
            "Epoch 42: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 10ms/step - loss: 0.9898 - accuracy: 0.6172 - val_loss: 0.9620 - val_accuracy: 0.6091\n",
            "Epoch 43/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9906 - accuracy: 0.6131\n",
            "Epoch 43: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9906 - accuracy: 0.6131 - val_loss: 0.9608 - val_accuracy: 0.6158\n",
            "Epoch 44/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9906 - accuracy: 0.6137\n",
            "Epoch 44: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9914 - accuracy: 0.6134 - val_loss: 0.9744 - val_accuracy: 0.6055\n",
            "Epoch 45/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9883 - accuracy: 0.6127\n",
            "Epoch 45: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 10ms/step - loss: 0.9882 - accuracy: 0.6125 - val_loss: 0.9636 - val_accuracy: 0.6075\n",
            "Epoch 46/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9846 - accuracy: 0.6171\n",
            "Epoch 46: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9821 - accuracy: 0.6181 - val_loss: 0.9616 - val_accuracy: 0.6206\n",
            "Epoch 47/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9823 - accuracy: 0.6141\n",
            "Epoch 47: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9827 - accuracy: 0.6138 - val_loss: 0.9486 - val_accuracy: 0.6162\n",
            "Epoch 48/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9781 - accuracy: 0.6198\n",
            "Epoch 48: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9795 - accuracy: 0.6199 - val_loss: 0.9570 - val_accuracy: 0.6178\n",
            "Epoch 49/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9784 - accuracy: 0.6176\n",
            "Epoch 49: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9788 - accuracy: 0.6173 - val_loss: 0.9524 - val_accuracy: 0.6135\n",
            "Epoch 50/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9744 - accuracy: 0.6240\n",
            "Epoch 50: saving model to l1norm_pruning_itr_2.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9748 - accuracy: 0.6235 - val_loss: 0.9554 - val_accuracy: 0.6150\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9554 - accuracy: 0.6150\n",
            "Sparsity: 0.40329008505176805 | val loss: 0.9554064869880676 | val acc: 0.6150494813919067\n",
            "Epoch 1/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.4930 - accuracy: 0.3577\n",
            "Epoch 1: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.4862 - accuracy: 0.3613 - val_loss: 1.2732 - val_accuracy: 0.4848\n",
            "Epoch 2/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.2585 - accuracy: 0.4837\n",
            "Epoch 2: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2583 - accuracy: 0.4840 - val_loss: 1.1899 - val_accuracy: 0.5113\n",
            "Epoch 3/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.2057 - accuracy: 0.5105\n",
            "Epoch 3: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2057 - accuracy: 0.5105 - val_loss: 1.1904 - val_accuracy: 0.5105\n",
            "Epoch 4/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.1797 - accuracy: 0.5249\n",
            "Epoch 4: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 10ms/step - loss: 1.1797 - accuracy: 0.5251 - val_loss: 1.1393 - val_accuracy: 0.5378\n",
            "Epoch 5/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.1604 - accuracy: 0.5359\n",
            "Epoch 5: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1593 - accuracy: 0.5364 - val_loss: 1.1100 - val_accuracy: 0.5592\n",
            "Epoch 6/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.1438 - accuracy: 0.5460\n",
            "Epoch 6: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1437 - accuracy: 0.5455 - val_loss: 1.1099 - val_accuracy: 0.5525\n",
            "Epoch 7/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.1323 - accuracy: 0.5505\n",
            "Epoch 7: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1325 - accuracy: 0.5498 - val_loss: 1.0825 - val_accuracy: 0.5636\n",
            "Epoch 8/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.1186 - accuracy: 0.5562\n",
            "Epoch 8: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1175 - accuracy: 0.5566 - val_loss: 1.0777 - val_accuracy: 0.5679\n",
            "Epoch 9/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1102 - accuracy: 0.5607\n",
            "Epoch 9: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1102 - accuracy: 0.5606 - val_loss: 1.0693 - val_accuracy: 0.5711\n",
            "Epoch 10/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0990 - accuracy: 0.5647\n",
            "Epoch 10: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0986 - accuracy: 0.5648 - val_loss: 1.0740 - val_accuracy: 0.5747\n",
            "Epoch 11/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0952 - accuracy: 0.5671\n",
            "Epoch 11: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0952 - accuracy: 0.5673 - val_loss: 1.0660 - val_accuracy: 0.5770\n",
            "Epoch 12/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0856 - accuracy: 0.5680\n",
            "Epoch 12: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0851 - accuracy: 0.5690 - val_loss: 1.0499 - val_accuracy: 0.5798\n",
            "Epoch 13/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0820 - accuracy: 0.5753\n",
            "Epoch 13: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0818 - accuracy: 0.5756 - val_loss: 1.0390 - val_accuracy: 0.5850\n",
            "Epoch 14/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0727 - accuracy: 0.5757\n",
            "Epoch 14: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0721 - accuracy: 0.5760 - val_loss: 1.0407 - val_accuracy: 0.5806\n",
            "Epoch 15/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0672 - accuracy: 0.5779\n",
            "Epoch 15: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0674 - accuracy: 0.5782 - val_loss: 1.0255 - val_accuracy: 0.5865\n",
            "Epoch 16/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0587 - accuracy: 0.5837\n",
            "Epoch 16: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0594 - accuracy: 0.5834 - val_loss: 1.0240 - val_accuracy: 0.5901\n",
            "Epoch 17/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0562 - accuracy: 0.5831\n",
            "Epoch 17: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0559 - accuracy: 0.5829 - val_loss: 1.0412 - val_accuracy: 0.5667\n",
            "Epoch 18/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0502 - accuracy: 0.5862\n",
            "Epoch 18: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0485 - accuracy: 0.5871 - val_loss: 1.0255 - val_accuracy: 0.5917\n",
            "Epoch 19/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0450 - accuracy: 0.5892\n",
            "Epoch 19: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0449 - accuracy: 0.5892 - val_loss: 1.0078 - val_accuracy: 0.5909\n",
            "Epoch 20/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0397 - accuracy: 0.5902\n",
            "Epoch 20: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0402 - accuracy: 0.5896 - val_loss: 0.9966 - val_accuracy: 0.5952\n",
            "Epoch 21/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0363 - accuracy: 0.5942\n",
            "Epoch 21: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0357 - accuracy: 0.5945 - val_loss: 1.0023 - val_accuracy: 0.5897\n",
            "Epoch 22/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0316 - accuracy: 0.5955\n",
            "Epoch 22: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0321 - accuracy: 0.5952 - val_loss: 0.9937 - val_accuracy: 0.6040\n",
            "Epoch 23/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0265 - accuracy: 0.5975\n",
            "Epoch 23: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0282 - accuracy: 0.5971 - val_loss: 1.0066 - val_accuracy: 0.5913\n",
            "Epoch 24/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0228 - accuracy: 0.5998\n",
            "Epoch 24: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0229 - accuracy: 0.5995 - val_loss: 1.0130 - val_accuracy: 0.5929\n",
            "Epoch 25/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0173 - accuracy: 0.5992\n",
            "Epoch 25: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0187 - accuracy: 0.5992 - val_loss: 0.9899 - val_accuracy: 0.6048\n",
            "Epoch 26/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0129 - accuracy: 0.6049\n",
            "Epoch 26: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0125 - accuracy: 0.6050 - val_loss: 0.9799 - val_accuracy: 0.6032\n",
            "Epoch 27/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0062 - accuracy: 0.6077\n",
            "Epoch 27: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0059 - accuracy: 0.6079 - val_loss: 0.9868 - val_accuracy: 0.6063\n",
            "Epoch 28/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9992 - accuracy: 0.6066\n",
            "Epoch 28: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9995 - accuracy: 0.6069 - val_loss: 0.9672 - val_accuracy: 0.6087\n",
            "Epoch 29/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0032 - accuracy: 0.6094\n",
            "Epoch 29: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0028 - accuracy: 0.6095 - val_loss: 0.9723 - val_accuracy: 0.6150\n",
            "Epoch 30/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9967 - accuracy: 0.6119\n",
            "Epoch 30: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9964 - accuracy: 0.6121 - val_loss: 0.9600 - val_accuracy: 0.6158\n",
            "Epoch 31/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9889 - accuracy: 0.6153\n",
            "Epoch 31: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9889 - accuracy: 0.6158 - val_loss: 0.9612 - val_accuracy: 0.6154\n",
            "Epoch 32/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9854 - accuracy: 0.6143\n",
            "Epoch 32: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9848 - accuracy: 0.6142 - val_loss: 0.9632 - val_accuracy: 0.6099\n",
            "Epoch 33/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9821 - accuracy: 0.6175\n",
            "Epoch 33: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9828 - accuracy: 0.6168 - val_loss: 0.9544 - val_accuracy: 0.6194\n",
            "Epoch 34/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9836 - accuracy: 0.6174\n",
            "Epoch 34: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9833 - accuracy: 0.6177 - val_loss: 0.9435 - val_accuracy: 0.6230\n",
            "Epoch 35/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9750 - accuracy: 0.6180\n",
            "Epoch 35: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9737 - accuracy: 0.6186 - val_loss: 0.9411 - val_accuracy: 0.6285\n",
            "Epoch 36/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9689 - accuracy: 0.6225\n",
            "Epoch 36: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9687 - accuracy: 0.6226 - val_loss: 0.9418 - val_accuracy: 0.6297\n",
            "Epoch 37/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9663 - accuracy: 0.6245\n",
            "Epoch 37: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9648 - accuracy: 0.6250 - val_loss: 0.9495 - val_accuracy: 0.6154\n",
            "Epoch 38/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9690 - accuracy: 0.6252\n",
            "Epoch 38: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9701 - accuracy: 0.6254 - val_loss: 0.9696 - val_accuracy: 0.6150\n",
            "Epoch 39/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9543 - accuracy: 0.6302\n",
            "Epoch 39: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9556 - accuracy: 0.6297 - val_loss: 0.9348 - val_accuracy: 0.6265\n",
            "Epoch 40/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9493 - accuracy: 0.6306\n",
            "Epoch 40: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9491 - accuracy: 0.6307 - val_loss: 0.9280 - val_accuracy: 0.6289\n",
            "Epoch 41/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9476 - accuracy: 0.6331\n",
            "Epoch 41: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9472 - accuracy: 0.6334 - val_loss: 0.9393 - val_accuracy: 0.6234\n",
            "Epoch 42/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9448 - accuracy: 0.6337\n",
            "Epoch 42: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9444 - accuracy: 0.6339 - val_loss: 0.9321 - val_accuracy: 0.6246\n",
            "Epoch 43/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9438 - accuracy: 0.6353\n",
            "Epoch 43: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9432 - accuracy: 0.6351 - val_loss: 0.9337 - val_accuracy: 0.6218\n",
            "Epoch 44/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9403 - accuracy: 0.6371\n",
            "Epoch 44: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9403 - accuracy: 0.6372 - val_loss: 0.9168 - val_accuracy: 0.6341\n",
            "Epoch 45/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9288 - accuracy: 0.6380\n",
            "Epoch 45: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9296 - accuracy: 0.6379 - val_loss: 0.9187 - val_accuracy: 0.6349\n",
            "Epoch 46/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9290 - accuracy: 0.6411\n",
            "Epoch 46: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9294 - accuracy: 0.6410 - val_loss: 0.9171 - val_accuracy: 0.6317\n",
            "Epoch 47/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9290 - accuracy: 0.6394\n",
            "Epoch 47: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9305 - accuracy: 0.6385 - val_loss: 0.9102 - val_accuracy: 0.6404\n",
            "Epoch 48/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9220 - accuracy: 0.6419\n",
            "Epoch 48: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9228 - accuracy: 0.6424 - val_loss: 0.9041 - val_accuracy: 0.6424\n",
            "Epoch 49/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9194 - accuracy: 0.6446\n",
            "Epoch 49: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9190 - accuracy: 0.6447 - val_loss: 0.9107 - val_accuracy: 0.6352\n",
            "Epoch 50/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9154 - accuracy: 0.6442\n",
            "Epoch 50: saving model to l1norm_pruning_itr_3.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9137 - accuracy: 0.6452 - val_loss: 0.9018 - val_accuracy: 0.6388\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9018 - accuracy: 0.6388\n",
            "Sparsity: 0.42633316074497457 | val loss: 0.9017761945724487 | val acc: 0.6388118863105774\n",
            "Epoch 1/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.4672 - accuracy: 0.3854\n",
            "Epoch 1: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.4657 - accuracy: 0.3862 - val_loss: 1.2430 - val_accuracy: 0.4891\n",
            "Epoch 2/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.2226 - accuracy: 0.5044\n",
            "Epoch 2: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2222 - accuracy: 0.5046 - val_loss: 1.1616 - val_accuracy: 0.5236\n",
            "Epoch 3/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.1862 - accuracy: 0.5189\n",
            "Epoch 3: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1871 - accuracy: 0.5188 - val_loss: 1.1254 - val_accuracy: 0.5370\n",
            "Epoch 4/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.1610 - accuracy: 0.5361\n",
            "Epoch 4: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1620 - accuracy: 0.5356 - val_loss: 1.1232 - val_accuracy: 0.5339\n",
            "Epoch 5/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.1455 - accuracy: 0.5387\n",
            "Epoch 5: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1456 - accuracy: 0.5382 - val_loss: 1.0923 - val_accuracy: 0.5537\n",
            "Epoch 6/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.1276 - accuracy: 0.5491\n",
            "Epoch 6: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1275 - accuracy: 0.5491 - val_loss: 1.0903 - val_accuracy: 0.5576\n",
            "Epoch 7/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1176 - accuracy: 0.5528\n",
            "Epoch 7: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1174 - accuracy: 0.5525 - val_loss: 1.0827 - val_accuracy: 0.5517\n",
            "Epoch 8/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.1015 - accuracy: 0.5603\n",
            "Epoch 8: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1015 - accuracy: 0.5606 - val_loss: 1.0574 - val_accuracy: 0.5818\n",
            "Epoch 9/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.1025 - accuracy: 0.5631\n",
            "Epoch 9: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1028 - accuracy: 0.5635 - val_loss: 1.0683 - val_accuracy: 0.5731\n",
            "Epoch 10/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0852 - accuracy: 0.5688\n",
            "Epoch 10: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0855 - accuracy: 0.5688 - val_loss: 1.0541 - val_accuracy: 0.5727\n",
            "Epoch 11/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0802 - accuracy: 0.5702\n",
            "Epoch 11: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0805 - accuracy: 0.5702 - val_loss: 1.0302 - val_accuracy: 0.5853\n",
            "Epoch 12/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.0692 - accuracy: 0.5746\n",
            "Epoch 12: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0692 - accuracy: 0.5746 - val_loss: 1.0303 - val_accuracy: 0.5814\n",
            "Epoch 13/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0588 - accuracy: 0.5809\n",
            "Epoch 13: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0583 - accuracy: 0.5806 - val_loss: 1.0257 - val_accuracy: 0.5857\n",
            "Epoch 14/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0590 - accuracy: 0.5833\n",
            "Epoch 14: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0587 - accuracy: 0.5834 - val_loss: 1.0257 - val_accuracy: 0.5842\n",
            "Epoch 15/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0484 - accuracy: 0.5845\n",
            "Epoch 15: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0486 - accuracy: 0.5842 - val_loss: 1.0098 - val_accuracy: 0.5889\n",
            "Epoch 16/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0426 - accuracy: 0.5908\n",
            "Epoch 16: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0419 - accuracy: 0.5918 - val_loss: 1.0323 - val_accuracy: 0.5909\n",
            "Epoch 17/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0384 - accuracy: 0.5911\n",
            "Epoch 17: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0384 - accuracy: 0.5913 - val_loss: 1.0116 - val_accuracy: 0.5889\n",
            "Epoch 18/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0253 - accuracy: 0.5963\n",
            "Epoch 18: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0251 - accuracy: 0.5965 - val_loss: 0.9875 - val_accuracy: 0.6044\n",
            "Epoch 19/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0259 - accuracy: 0.5985\n",
            "Epoch 19: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0255 - accuracy: 0.5987 - val_loss: 0.9868 - val_accuracy: 0.6111\n",
            "Epoch 20/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0175 - accuracy: 0.6005\n",
            "Epoch 20: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0184 - accuracy: 0.6002 - val_loss: 1.0182 - val_accuracy: 0.5972\n",
            "Epoch 21/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0148 - accuracy: 0.6031\n",
            "Epoch 21: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0140 - accuracy: 0.6033 - val_loss: 0.9894 - val_accuracy: 0.6016\n",
            "Epoch 22/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0064 - accuracy: 0.6049\n",
            "Epoch 22: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0062 - accuracy: 0.6052 - val_loss: 0.9716 - val_accuracy: 0.6119\n",
            "Epoch 23/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0031 - accuracy: 0.6045\n",
            "Epoch 23: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0037 - accuracy: 0.6039 - val_loss: 0.9840 - val_accuracy: 0.6111\n",
            "Epoch 24/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0012 - accuracy: 0.6093\n",
            "Epoch 24: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0018 - accuracy: 0.6088 - val_loss: 0.9657 - val_accuracy: 0.6091\n",
            "Epoch 25/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9913 - accuracy: 0.6121\n",
            "Epoch 25: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9911 - accuracy: 0.6121 - val_loss: 0.9637 - val_accuracy: 0.6158\n",
            "Epoch 26/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9900 - accuracy: 0.6112\n",
            "Epoch 26: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9898 - accuracy: 0.6112 - val_loss: 0.9654 - val_accuracy: 0.6087\n",
            "Epoch 27/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9843 - accuracy: 0.6153\n",
            "Epoch 27: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9843 - accuracy: 0.6153 - val_loss: 0.9532 - val_accuracy: 0.6154\n",
            "Epoch 28/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9854 - accuracy: 0.6142\n",
            "Epoch 28: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9861 - accuracy: 0.6142 - val_loss: 0.9485 - val_accuracy: 0.6226\n",
            "Epoch 29/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9749 - accuracy: 0.6188\n",
            "Epoch 29: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9765 - accuracy: 0.6187 - val_loss: 0.9574 - val_accuracy: 0.6170\n",
            "Epoch 30/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9747 - accuracy: 0.6197\n",
            "Epoch 30: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9747 - accuracy: 0.6197 - val_loss: 0.9531 - val_accuracy: 0.6202\n",
            "Epoch 31/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9710 - accuracy: 0.6208\n",
            "Epoch 31: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9700 - accuracy: 0.6216 - val_loss: 0.9517 - val_accuracy: 0.6198\n",
            "Epoch 32/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9618 - accuracy: 0.6253\n",
            "Epoch 32: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9625 - accuracy: 0.6245 - val_loss: 0.9347 - val_accuracy: 0.6246\n",
            "Epoch 33/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9631 - accuracy: 0.6249\n",
            "Epoch 33: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9624 - accuracy: 0.6255 - val_loss: 0.9335 - val_accuracy: 0.6257\n",
            "Epoch 34/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9608 - accuracy: 0.6259\n",
            "Epoch 34: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9609 - accuracy: 0.6259 - val_loss: 0.9408 - val_accuracy: 0.6273\n",
            "Epoch 35/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9536 - accuracy: 0.6282\n",
            "Epoch 35: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9536 - accuracy: 0.6282 - val_loss: 0.9329 - val_accuracy: 0.6257\n",
            "Epoch 36/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9528 - accuracy: 0.6299\n",
            "Epoch 36: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9537 - accuracy: 0.6298 - val_loss: 0.9294 - val_accuracy: 0.6285\n",
            "Epoch 37/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9443 - accuracy: 0.6353\n",
            "Epoch 37: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9451 - accuracy: 0.6346 - val_loss: 0.9211 - val_accuracy: 0.6337\n",
            "Epoch 38/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9435 - accuracy: 0.6322\n",
            "Epoch 38: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9430 - accuracy: 0.6319 - val_loss: 0.9555 - val_accuracy: 0.6285\n",
            "Epoch 39/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9367 - accuracy: 0.6337\n",
            "Epoch 39: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9367 - accuracy: 0.6337 - val_loss: 0.9256 - val_accuracy: 0.6234\n",
            "Epoch 40/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9414 - accuracy: 0.6337\n",
            "Epoch 40: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9411 - accuracy: 0.6338 - val_loss: 0.9119 - val_accuracy: 0.6341\n",
            "Epoch 41/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9325 - accuracy: 0.6377\n",
            "Epoch 41: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9325 - accuracy: 0.6377 - val_loss: 0.9103 - val_accuracy: 0.6341\n",
            "Epoch 42/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9205 - accuracy: 0.6438\n",
            "Epoch 42: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9210 - accuracy: 0.6435 - val_loss: 0.9258 - val_accuracy: 0.6182\n",
            "Epoch 43/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9294 - accuracy: 0.6410\n",
            "Epoch 43: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9292 - accuracy: 0.6411 - val_loss: 0.9176 - val_accuracy: 0.6297\n",
            "Epoch 44/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9233 - accuracy: 0.6416\n",
            "Epoch 44: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9233 - accuracy: 0.6416 - val_loss: 0.9116 - val_accuracy: 0.6400\n",
            "Epoch 45/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9187 - accuracy: 0.6456\n",
            "Epoch 45: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9187 - accuracy: 0.6456 - val_loss: 0.9198 - val_accuracy: 0.6305\n",
            "Epoch 46/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9150 - accuracy: 0.6442\n",
            "Epoch 46: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9157 - accuracy: 0.6439 - val_loss: 0.8994 - val_accuracy: 0.6444\n",
            "Epoch 47/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9112 - accuracy: 0.6465\n",
            "Epoch 47: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9122 - accuracy: 0.6465 - val_loss: 0.9073 - val_accuracy: 0.6400\n",
            "Epoch 48/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9123 - accuracy: 0.6456\n",
            "Epoch 48: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9113 - accuracy: 0.6462 - val_loss: 0.9061 - val_accuracy: 0.6341\n",
            "Epoch 49/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9053 - accuracy: 0.6531\n",
            "Epoch 49: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9069 - accuracy: 0.6523 - val_loss: 0.8948 - val_accuracy: 0.6396\n",
            "Epoch 50/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9042 - accuracy: 0.6535\n",
            "Epoch 50: saving model to l1norm_pruning_itr_4.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9035 - accuracy: 0.6537 - val_loss: 0.9105 - val_accuracy: 0.6416\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9105 - accuracy: 0.6416\n",
            "Sparsity: 0.4546112292619908 | val loss: 0.9104577302932739 | val acc: 0.6415841579437256\n",
            "Epoch 1/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.4596 - accuracy: 0.4049\n",
            "Epoch 1: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.4577 - accuracy: 0.4055 - val_loss: 1.2421 - val_accuracy: 0.4796\n",
            "Epoch 2/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.2153 - accuracy: 0.5104\n",
            "Epoch 2: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.2149 - accuracy: 0.5109 - val_loss: 1.1473 - val_accuracy: 0.5311\n",
            "Epoch 3/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.1682 - accuracy: 0.5292\n",
            "Epoch 3: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1682 - accuracy: 0.5292 - val_loss: 1.1137 - val_accuracy: 0.5390\n",
            "Epoch 4/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.1398 - accuracy: 0.5472\n",
            "Epoch 4: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1398 - accuracy: 0.5472 - val_loss: 1.1032 - val_accuracy: 0.5442\n",
            "Epoch 5/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.1244 - accuracy: 0.5551\n",
            "Epoch 5: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1243 - accuracy: 0.5556 - val_loss: 1.0703 - val_accuracy: 0.5655\n",
            "Epoch 6/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.1113 - accuracy: 0.5583\n",
            "Epoch 6: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1116 - accuracy: 0.5579 - val_loss: 1.0594 - val_accuracy: 0.5711\n",
            "Epoch 7/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1082 - accuracy: 0.5596\n",
            "Epoch 7: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1075 - accuracy: 0.5600 - val_loss: 1.0706 - val_accuracy: 0.5596\n",
            "Epoch 8/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0873 - accuracy: 0.5708\n",
            "Epoch 8: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0887 - accuracy: 0.5696 - val_loss: 1.0489 - val_accuracy: 0.5711\n",
            "Epoch 9/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0782 - accuracy: 0.5743\n",
            "Epoch 9: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0775 - accuracy: 0.5749 - val_loss: 1.0318 - val_accuracy: 0.5881\n",
            "Epoch 10/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0788 - accuracy: 0.5726\n",
            "Epoch 10: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0779 - accuracy: 0.5730 - val_loss: 1.0285 - val_accuracy: 0.5814\n",
            "Epoch 11/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0613 - accuracy: 0.5802\n",
            "Epoch 11: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0601 - accuracy: 0.5806 - val_loss: 1.0209 - val_accuracy: 0.5794\n",
            "Epoch 12/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0570 - accuracy: 0.5825\n",
            "Epoch 12: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0587 - accuracy: 0.5813 - val_loss: 1.0155 - val_accuracy: 0.5913\n",
            "Epoch 13/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0562 - accuracy: 0.5821\n",
            "Epoch 13: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0561 - accuracy: 0.5820 - val_loss: 1.0245 - val_accuracy: 0.5786\n",
            "Epoch 14/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0423 - accuracy: 0.5877\n",
            "Epoch 14: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0427 - accuracy: 0.5878 - val_loss: 1.0264 - val_accuracy: 0.5909\n",
            "Epoch 15/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.0385 - accuracy: 0.5902\n",
            "Epoch 15: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0385 - accuracy: 0.5902 - val_loss: 1.0193 - val_accuracy: 0.5814\n",
            "Epoch 16/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0345 - accuracy: 0.5962\n",
            "Epoch 16: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0346 - accuracy: 0.5955 - val_loss: 0.9957 - val_accuracy: 0.5925\n",
            "Epoch 17/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0293 - accuracy: 0.5930\n",
            "Epoch 17: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0291 - accuracy: 0.5931 - val_loss: 0.9938 - val_accuracy: 0.5956\n",
            "Epoch 18/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0204 - accuracy: 0.6000\n",
            "Epoch 18: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0209 - accuracy: 0.5999 - val_loss: 1.0006 - val_accuracy: 0.5881\n",
            "Epoch 19/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0151 - accuracy: 0.6011\n",
            "Epoch 19: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0163 - accuracy: 0.6011 - val_loss: 0.9869 - val_accuracy: 0.5980\n",
            "Epoch 20/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0150 - accuracy: 0.6017\n",
            "Epoch 20: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0147 - accuracy: 0.6020 - val_loss: 0.9870 - val_accuracy: 0.5921\n",
            "Epoch 21/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0117 - accuracy: 0.5999\n",
            "Epoch 21: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0117 - accuracy: 0.6001 - val_loss: 0.9699 - val_accuracy: 0.6127\n",
            "Epoch 22/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0080 - accuracy: 0.6055\n",
            "Epoch 22: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0086 - accuracy: 0.6052 - val_loss: 0.9815 - val_accuracy: 0.6063\n",
            "Epoch 23/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0049 - accuracy: 0.6043\n",
            "Epoch 23: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0049 - accuracy: 0.6049 - val_loss: 0.9640 - val_accuracy: 0.6135\n",
            "Epoch 24/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9987 - accuracy: 0.6109\n",
            "Epoch 24: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9986 - accuracy: 0.6110 - val_loss: 0.9741 - val_accuracy: 0.6079\n",
            "Epoch 25/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9954 - accuracy: 0.6098\n",
            "Epoch 25: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9944 - accuracy: 0.6101 - val_loss: 0.9794 - val_accuracy: 0.6012\n",
            "Epoch 26/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9918 - accuracy: 0.6109\n",
            "Epoch 26: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9918 - accuracy: 0.6109 - val_loss: 0.9703 - val_accuracy: 0.6099\n",
            "Epoch 27/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9922 - accuracy: 0.6135\n",
            "Epoch 27: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9910 - accuracy: 0.6140 - val_loss: 0.9574 - val_accuracy: 0.6238\n",
            "Epoch 28/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9853 - accuracy: 0.6143\n",
            "Epoch 28: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9853 - accuracy: 0.6143 - val_loss: 0.9562 - val_accuracy: 0.6131\n",
            "Epoch 29/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9817 - accuracy: 0.6165\n",
            "Epoch 29: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9805 - accuracy: 0.6172 - val_loss: 0.9640 - val_accuracy: 0.6150\n",
            "Epoch 30/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9798 - accuracy: 0.6168\n",
            "Epoch 30: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9802 - accuracy: 0.6166 - val_loss: 0.9482 - val_accuracy: 0.6174\n",
            "Epoch 31/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9728 - accuracy: 0.6207\n",
            "Epoch 31: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9739 - accuracy: 0.6201 - val_loss: 0.9508 - val_accuracy: 0.6242\n",
            "Epoch 32/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9705 - accuracy: 0.6196\n",
            "Epoch 32: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9715 - accuracy: 0.6190 - val_loss: 0.9401 - val_accuracy: 0.6246\n",
            "Epoch 33/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9691 - accuracy: 0.6201\n",
            "Epoch 33: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9703 - accuracy: 0.6197 - val_loss: 0.9490 - val_accuracy: 0.6206\n",
            "Epoch 34/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9688 - accuracy: 0.6240\n",
            "Epoch 34: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9692 - accuracy: 0.6236 - val_loss: 0.9320 - val_accuracy: 0.6234\n",
            "Epoch 35/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9646 - accuracy: 0.6250\n",
            "Epoch 35: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9646 - accuracy: 0.6250 - val_loss: 0.9408 - val_accuracy: 0.6131\n",
            "Epoch 36/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9537 - accuracy: 0.6286\n",
            "Epoch 36: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9549 - accuracy: 0.6281 - val_loss: 0.9480 - val_accuracy: 0.6186\n",
            "Epoch 37/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9556 - accuracy: 0.6312\n",
            "Epoch 37: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9557 - accuracy: 0.6310 - val_loss: 0.9654 - val_accuracy: 0.6123\n",
            "Epoch 38/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9556 - accuracy: 0.6299\n",
            "Epoch 38: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9557 - accuracy: 0.6297 - val_loss: 0.9300 - val_accuracy: 0.6250\n",
            "Epoch 39/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9604 - accuracy: 0.6275\n",
            "Epoch 39: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9602 - accuracy: 0.6279 - val_loss: 0.9581 - val_accuracy: 0.6150\n",
            "Epoch 40/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9493 - accuracy: 0.6338\n",
            "Epoch 40: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9497 - accuracy: 0.6336 - val_loss: 0.9387 - val_accuracy: 0.6186\n",
            "Epoch 41/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9428 - accuracy: 0.6318\n",
            "Epoch 41: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9427 - accuracy: 0.6315 - val_loss: 0.9459 - val_accuracy: 0.6198\n",
            "Epoch 42/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9400 - accuracy: 0.6354\n",
            "Epoch 42: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9405 - accuracy: 0.6349 - val_loss: 0.9182 - val_accuracy: 0.6317\n",
            "Epoch 43/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9421 - accuracy: 0.6343\n",
            "Epoch 43: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9417 - accuracy: 0.6348 - val_loss: 0.9281 - val_accuracy: 0.6198\n",
            "Epoch 44/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9372 - accuracy: 0.6369\n",
            "Epoch 44: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9372 - accuracy: 0.6369 - val_loss: 0.9222 - val_accuracy: 0.6265\n",
            "Epoch 45/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9341 - accuracy: 0.6357\n",
            "Epoch 45: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9341 - accuracy: 0.6357 - val_loss: 0.9228 - val_accuracy: 0.6226\n",
            "Epoch 46/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9331 - accuracy: 0.6392\n",
            "Epoch 46: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9334 - accuracy: 0.6392 - val_loss: 0.9200 - val_accuracy: 0.6352\n",
            "Epoch 47/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9249 - accuracy: 0.6426\n",
            "Epoch 47: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9248 - accuracy: 0.6432 - val_loss: 0.9320 - val_accuracy: 0.6186\n",
            "Epoch 48/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9253 - accuracy: 0.6396\n",
            "Epoch 48: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9258 - accuracy: 0.6397 - val_loss: 0.9087 - val_accuracy: 0.6317\n",
            "Epoch 49/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9309 - accuracy: 0.6384\n",
            "Epoch 49: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9313 - accuracy: 0.6381 - val_loss: 0.9078 - val_accuracy: 0.6364\n",
            "Epoch 50/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9267 - accuracy: 0.6386\n",
            "Epoch 50: saving model to l1norm_pruning_itr_5.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9267 - accuracy: 0.6386 - val_loss: 0.9089 - val_accuracy: 0.6440\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9089 - accuracy: 0.6440\n",
            "Sparsity: 0.47507897182312336 | val loss: 0.9088923335075378 | val acc: 0.6439604163169861\n",
            "Epoch 1/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.3995 - accuracy: 0.4363\n",
            "Epoch 1: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.3951 - accuracy: 0.4370 - val_loss: 1.1597 - val_accuracy: 0.5232\n",
            "Epoch 2/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1641 - accuracy: 0.5317\n",
            "Epoch 2: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1627 - accuracy: 0.5324 - val_loss: 1.1070 - val_accuracy: 0.5493\n",
            "Epoch 3/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.1361 - accuracy: 0.5450\n",
            "Epoch 3: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1360 - accuracy: 0.5449 - val_loss: 1.0741 - val_accuracy: 0.5592\n",
            "Epoch 4/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.1132 - accuracy: 0.5581\n",
            "Epoch 4: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1128 - accuracy: 0.5580 - val_loss: 1.0546 - val_accuracy: 0.5648\n",
            "Epoch 5/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0941 - accuracy: 0.5672\n",
            "Epoch 5: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0939 - accuracy: 0.5672 - val_loss: 1.0466 - val_accuracy: 0.5703\n",
            "Epoch 6/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0825 - accuracy: 0.5719\n",
            "Epoch 6: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0828 - accuracy: 0.5718 - val_loss: 1.0391 - val_accuracy: 0.5770\n",
            "Epoch 7/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0704 - accuracy: 0.5795\n",
            "Epoch 7: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0701 - accuracy: 0.5794 - val_loss: 1.0189 - val_accuracy: 0.5818\n",
            "Epoch 8/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0589 - accuracy: 0.5801\n",
            "Epoch 8: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0595 - accuracy: 0.5798 - val_loss: 1.0080 - val_accuracy: 0.5976\n",
            "Epoch 9/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0608 - accuracy: 0.5819\n",
            "Epoch 9: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0612 - accuracy: 0.5816 - val_loss: 1.0058 - val_accuracy: 0.5913\n",
            "Epoch 10/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0472 - accuracy: 0.5873\n",
            "Epoch 10: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0471 - accuracy: 0.5873 - val_loss: 1.0064 - val_accuracy: 0.5893\n",
            "Epoch 11/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0410 - accuracy: 0.5900\n",
            "Epoch 11: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0422 - accuracy: 0.5891 - val_loss: 0.9875 - val_accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0355 - accuracy: 0.5885\n",
            "Epoch 12: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0351 - accuracy: 0.5886 - val_loss: 0.9857 - val_accuracy: 0.5988\n",
            "Epoch 13/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0242 - accuracy: 0.5907\n",
            "Epoch 13: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0249 - accuracy: 0.5906 - val_loss: 0.9808 - val_accuracy: 0.5976\n",
            "Epoch 14/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0179 - accuracy: 0.5982\n",
            "Epoch 14: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0177 - accuracy: 0.5981 - val_loss: 0.9827 - val_accuracy: 0.5996\n",
            "Epoch 15/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0120 - accuracy: 0.6067\n",
            "Epoch 15: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0122 - accuracy: 0.6065 - val_loss: 0.9687 - val_accuracy: 0.6079\n",
            "Epoch 16/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0130 - accuracy: 0.6047\n",
            "Epoch 16: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0123 - accuracy: 0.6053 - val_loss: 0.9680 - val_accuracy: 0.6087\n",
            "Epoch 17/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0013 - accuracy: 0.6074\n",
            "Epoch 17: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0013 - accuracy: 0.6074 - val_loss: 0.9690 - val_accuracy: 0.6032\n",
            "Epoch 18/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0013 - accuracy: 0.6067\n",
            "Epoch 18: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9997 - accuracy: 0.6071 - val_loss: 0.9697 - val_accuracy: 0.6071\n",
            "Epoch 19/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9930 - accuracy: 0.6097\n",
            "Epoch 19: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9930 - accuracy: 0.6097 - val_loss: 0.9701 - val_accuracy: 0.6040\n",
            "Epoch 20/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9886 - accuracy: 0.6111\n",
            "Epoch 20: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9879 - accuracy: 0.6121 - val_loss: 0.9619 - val_accuracy: 0.6040\n",
            "Epoch 21/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9841 - accuracy: 0.6184\n",
            "Epoch 21: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9845 - accuracy: 0.6183 - val_loss: 0.9487 - val_accuracy: 0.6150\n",
            "Epoch 22/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9857 - accuracy: 0.6170\n",
            "Epoch 22: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9857 - accuracy: 0.6170 - val_loss: 0.9510 - val_accuracy: 0.6123\n",
            "Epoch 23/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9785 - accuracy: 0.6182\n",
            "Epoch 23: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9787 - accuracy: 0.6179 - val_loss: 0.9466 - val_accuracy: 0.6131\n",
            "Epoch 24/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9725 - accuracy: 0.6196\n",
            "Epoch 24: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9754 - accuracy: 0.6186 - val_loss: 0.9451 - val_accuracy: 0.6147\n",
            "Epoch 25/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9732 - accuracy: 0.6196\n",
            "Epoch 25: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9726 - accuracy: 0.6198 - val_loss: 0.9321 - val_accuracy: 0.6174\n",
            "Epoch 26/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9653 - accuracy: 0.6223\n",
            "Epoch 26: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9649 - accuracy: 0.6223 - val_loss: 0.9270 - val_accuracy: 0.6214\n",
            "Epoch 27/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9660 - accuracy: 0.6234\n",
            "Epoch 27: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9656 - accuracy: 0.6236 - val_loss: 0.9325 - val_accuracy: 0.6218\n",
            "Epoch 28/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9661 - accuracy: 0.6241\n",
            "Epoch 28: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9661 - accuracy: 0.6239 - val_loss: 0.9384 - val_accuracy: 0.6186\n",
            "Epoch 29/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9617 - accuracy: 0.6294\n",
            "Epoch 29: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9609 - accuracy: 0.6296 - val_loss: 0.9490 - val_accuracy: 0.6127\n",
            "Epoch 30/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9609 - accuracy: 0.6236\n",
            "Epoch 30: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9613 - accuracy: 0.6234 - val_loss: 0.9174 - val_accuracy: 0.6281\n",
            "Epoch 31/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9527 - accuracy: 0.6275\n",
            "Epoch 31: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9551 - accuracy: 0.6263 - val_loss: 0.9243 - val_accuracy: 0.6309\n",
            "Epoch 32/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9486 - accuracy: 0.6311\n",
            "Epoch 32: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9483 - accuracy: 0.6310 - val_loss: 0.9255 - val_accuracy: 0.6250\n",
            "Epoch 33/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9479 - accuracy: 0.6295\n",
            "Epoch 33: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9479 - accuracy: 0.6290 - val_loss: 0.9253 - val_accuracy: 0.6234\n",
            "Epoch 34/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9400 - accuracy: 0.6360\n",
            "Epoch 34: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9397 - accuracy: 0.6361 - val_loss: 0.9109 - val_accuracy: 0.6364\n",
            "Epoch 35/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9392 - accuracy: 0.6343\n",
            "Epoch 35: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9392 - accuracy: 0.6343 - val_loss: 0.9195 - val_accuracy: 0.6293\n",
            "Epoch 36/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9426 - accuracy: 0.6359\n",
            "Epoch 36: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9426 - accuracy: 0.6360 - val_loss: 0.9106 - val_accuracy: 0.6325\n",
            "Epoch 37/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9374 - accuracy: 0.6360\n",
            "Epoch 37: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9374 - accuracy: 0.6360 - val_loss: 0.9065 - val_accuracy: 0.6321\n",
            "Epoch 38/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9384 - accuracy: 0.6367\n",
            "Epoch 38: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9389 - accuracy: 0.6362 - val_loss: 0.9092 - val_accuracy: 0.6281\n",
            "Epoch 39/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9309 - accuracy: 0.6409\n",
            "Epoch 39: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9305 - accuracy: 0.6410 - val_loss: 0.9129 - val_accuracy: 0.6325\n",
            "Epoch 40/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9290 - accuracy: 0.6412\n",
            "Epoch 40: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9288 - accuracy: 0.6414 - val_loss: 0.8981 - val_accuracy: 0.6345\n",
            "Epoch 41/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9209 - accuracy: 0.6426\n",
            "Epoch 41: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9210 - accuracy: 0.6428 - val_loss: 0.8961 - val_accuracy: 0.6360\n",
            "Epoch 42/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9196 - accuracy: 0.6473\n",
            "Epoch 42: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9200 - accuracy: 0.6473 - val_loss: 0.8935 - val_accuracy: 0.6384\n",
            "Epoch 43/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9185 - accuracy: 0.6426\n",
            "Epoch 43: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9187 - accuracy: 0.6426 - val_loss: 0.8941 - val_accuracy: 0.6408\n",
            "Epoch 44/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9256 - accuracy: 0.6400\n",
            "Epoch 44: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9254 - accuracy: 0.6401 - val_loss: 0.8948 - val_accuracy: 0.6388\n",
            "Epoch 45/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9184 - accuracy: 0.6471\n",
            "Epoch 45: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9178 - accuracy: 0.6472 - val_loss: 0.9013 - val_accuracy: 0.6356\n",
            "Epoch 46/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9132 - accuracy: 0.6506\n",
            "Epoch 46: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9146 - accuracy: 0.6498 - val_loss: 0.9035 - val_accuracy: 0.6329\n",
            "Epoch 47/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9137 - accuracy: 0.6482\n",
            "Epoch 47: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9133 - accuracy: 0.6483 - val_loss: 0.8896 - val_accuracy: 0.6333\n",
            "Epoch 48/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9131 - accuracy: 0.6474\n",
            "Epoch 48: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9134 - accuracy: 0.6480 - val_loss: 0.8928 - val_accuracy: 0.6341\n",
            "Epoch 49/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9064 - accuracy: 0.6499\n",
            "Epoch 49: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9064 - accuracy: 0.6499 - val_loss: 0.8920 - val_accuracy: 0.6321\n",
            "Epoch 50/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9044 - accuracy: 0.6508\n",
            "Epoch 50: saving model to l1norm_pruning_itr_6.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9041 - accuracy: 0.6509 - val_loss: 0.8819 - val_accuracy: 0.6463\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8819 - accuracy: 0.6463\n",
            "Sparsity: 0.4958435438742657 | val loss: 0.8818788528442383 | val acc: 0.6463366150856018\n",
            "Epoch 1/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.3929 - accuracy: 0.4394\n",
            "Epoch 1: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.3923 - accuracy: 0.4397 - val_loss: 1.1439 - val_accuracy: 0.5291\n",
            "Epoch 2/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.1493 - accuracy: 0.5389\n",
            "Epoch 2: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1499 - accuracy: 0.5384 - val_loss: 1.0822 - val_accuracy: 0.5644\n",
            "Epoch 3/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.1154 - accuracy: 0.5556\n",
            "Epoch 3: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1149 - accuracy: 0.5564 - val_loss: 1.0619 - val_accuracy: 0.5707\n",
            "Epoch 4/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0912 - accuracy: 0.5646\n",
            "Epoch 4: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0908 - accuracy: 0.5652 - val_loss: 1.0541 - val_accuracy: 0.5703\n",
            "Epoch 5/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0803 - accuracy: 0.5743\n",
            "Epoch 5: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0789 - accuracy: 0.5750 - val_loss: 1.0238 - val_accuracy: 0.5905\n",
            "Epoch 6/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0684 - accuracy: 0.5800\n",
            "Epoch 6: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0678 - accuracy: 0.5803 - val_loss: 1.0126 - val_accuracy: 0.5905\n",
            "Epoch 7/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0532 - accuracy: 0.5857\n",
            "Epoch 7: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0533 - accuracy: 0.5854 - val_loss: 1.0111 - val_accuracy: 0.5897\n",
            "Epoch 8/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0543 - accuracy: 0.5863\n",
            "Epoch 8: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0538 - accuracy: 0.5865 - val_loss: 0.9976 - val_accuracy: 0.5937\n",
            "Epoch 9/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0400 - accuracy: 0.5861\n",
            "Epoch 9: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0418 - accuracy: 0.5856 - val_loss: 0.9875 - val_accuracy: 0.6071\n",
            "Epoch 10/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0353 - accuracy: 0.5970\n",
            "Epoch 10: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0358 - accuracy: 0.5965 - val_loss: 0.9907 - val_accuracy: 0.5897\n",
            "Epoch 11/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0318 - accuracy: 0.5987\n",
            "Epoch 11: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0318 - accuracy: 0.5986 - val_loss: 0.9940 - val_accuracy: 0.5937\n",
            "Epoch 12/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0194 - accuracy: 0.5966\n",
            "Epoch 12: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0208 - accuracy: 0.5953 - val_loss: 0.9880 - val_accuracy: 0.5949\n",
            "Epoch 13/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0182 - accuracy: 0.6019\n",
            "Epoch 13: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0188 - accuracy: 0.6016 - val_loss: 0.9636 - val_accuracy: 0.6063\n",
            "Epoch 14/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0122 - accuracy: 0.6054\n",
            "Epoch 14: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0101 - accuracy: 0.6069 - val_loss: 0.9650 - val_accuracy: 0.6095\n",
            "Epoch 15/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0081 - accuracy: 0.6069\n",
            "Epoch 15: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0083 - accuracy: 0.6067 - val_loss: 0.9571 - val_accuracy: 0.6091\n",
            "Epoch 16/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0024 - accuracy: 0.6062\n",
            "Epoch 16: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0032 - accuracy: 0.6060 - val_loss: 0.9516 - val_accuracy: 0.6139\n",
            "Epoch 17/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9990 - accuracy: 0.6120\n",
            "Epoch 17: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9994 - accuracy: 0.6117 - val_loss: 0.9639 - val_accuracy: 0.5956\n",
            "Epoch 18/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9919 - accuracy: 0.6128\n",
            "Epoch 18: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9917 - accuracy: 0.6126 - val_loss: 0.9413 - val_accuracy: 0.6214\n",
            "Epoch 19/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9876 - accuracy: 0.6130\n",
            "Epoch 19: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9876 - accuracy: 0.6130 - val_loss: 0.9567 - val_accuracy: 0.6115\n",
            "Epoch 20/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9867 - accuracy: 0.6153\n",
            "Epoch 20: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9871 - accuracy: 0.6160 - val_loss: 0.9480 - val_accuracy: 0.6154\n",
            "Epoch 21/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9795 - accuracy: 0.6173\n",
            "Epoch 21: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9798 - accuracy: 0.6168 - val_loss: 0.9341 - val_accuracy: 0.6154\n",
            "Epoch 22/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9738 - accuracy: 0.6231\n",
            "Epoch 22: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9743 - accuracy: 0.6219 - val_loss: 0.9421 - val_accuracy: 0.6147\n",
            "Epoch 23/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9750 - accuracy: 0.6205\n",
            "Epoch 23: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9751 - accuracy: 0.6198 - val_loss: 0.9534 - val_accuracy: 0.6051\n",
            "Epoch 24/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9721 - accuracy: 0.6219\n",
            "Epoch 24: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9713 - accuracy: 0.6219 - val_loss: 0.9533 - val_accuracy: 0.6123\n",
            "Epoch 25/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9714 - accuracy: 0.6214\n",
            "Epoch 25: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9714 - accuracy: 0.6214 - val_loss: 0.9451 - val_accuracy: 0.6139\n",
            "Epoch 26/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9697 - accuracy: 0.6248\n",
            "Epoch 26: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9697 - accuracy: 0.6248 - val_loss: 0.9219 - val_accuracy: 0.6218\n",
            "Epoch 27/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9622 - accuracy: 0.6266\n",
            "Epoch 27: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9616 - accuracy: 0.6272 - val_loss: 0.9377 - val_accuracy: 0.6206\n",
            "Epoch 28/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9637 - accuracy: 0.6248\n",
            "Epoch 28: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9617 - accuracy: 0.6255 - val_loss: 0.9208 - val_accuracy: 0.6210\n",
            "Epoch 29/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9547 - accuracy: 0.6303\n",
            "Epoch 29: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9548 - accuracy: 0.6312 - val_loss: 0.9244 - val_accuracy: 0.6158\n",
            "Epoch 30/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9532 - accuracy: 0.6289\n",
            "Epoch 30: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9532 - accuracy: 0.6286 - val_loss: 0.9196 - val_accuracy: 0.6246\n",
            "Epoch 31/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9538 - accuracy: 0.6292\n",
            "Epoch 31: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9535 - accuracy: 0.6292 - val_loss: 0.9271 - val_accuracy: 0.6206\n",
            "Epoch 32/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9514 - accuracy: 0.6302\n",
            "Epoch 32: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9493 - accuracy: 0.6311 - val_loss: 0.9248 - val_accuracy: 0.6257\n",
            "Epoch 33/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9448 - accuracy: 0.6305\n",
            "Epoch 33: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9450 - accuracy: 0.6312 - val_loss: 0.9228 - val_accuracy: 0.6301\n",
            "Epoch 34/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9425 - accuracy: 0.6390\n",
            "Epoch 34: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9424 - accuracy: 0.6387 - val_loss: 0.9071 - val_accuracy: 0.6297\n",
            "Epoch 35/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9418 - accuracy: 0.6362\n",
            "Epoch 35: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9432 - accuracy: 0.6351 - val_loss: 0.9121 - val_accuracy: 0.6289\n",
            "Epoch 36/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9425 - accuracy: 0.6350\n",
            "Epoch 36: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9428 - accuracy: 0.6352 - val_loss: 0.9055 - val_accuracy: 0.6309\n",
            "Epoch 37/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9310 - accuracy: 0.6369\n",
            "Epoch 37: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9304 - accuracy: 0.6372 - val_loss: 0.9034 - val_accuracy: 0.6349\n",
            "Epoch 38/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9331 - accuracy: 0.6372\n",
            "Epoch 38: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9327 - accuracy: 0.6374 - val_loss: 0.9149 - val_accuracy: 0.6380\n",
            "Epoch 39/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9302 - accuracy: 0.6437\n",
            "Epoch 39: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9279 - accuracy: 0.6446 - val_loss: 0.9050 - val_accuracy: 0.6392\n",
            "Epoch 40/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9299 - accuracy: 0.6392\n",
            "Epoch 40: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9302 - accuracy: 0.6390 - val_loss: 0.8931 - val_accuracy: 0.6455\n",
            "Epoch 41/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9228 - accuracy: 0.6448\n",
            "Epoch 41: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9235 - accuracy: 0.6446 - val_loss: 0.8969 - val_accuracy: 0.6352\n",
            "Epoch 42/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9150 - accuracy: 0.6445\n",
            "Epoch 42: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9162 - accuracy: 0.6436 - val_loss: 0.8964 - val_accuracy: 0.6313\n",
            "Epoch 43/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9196 - accuracy: 0.6442\n",
            "Epoch 43: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9197 - accuracy: 0.6443 - val_loss: 0.9095 - val_accuracy: 0.6317\n",
            "Epoch 44/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9136 - accuracy: 0.6495\n",
            "Epoch 44: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9134 - accuracy: 0.6496 - val_loss: 0.9015 - val_accuracy: 0.6364\n",
            "Epoch 45/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9116 - accuracy: 0.6492\n",
            "Epoch 45: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9119 - accuracy: 0.6490 - val_loss: 0.9028 - val_accuracy: 0.6317\n",
            "Epoch 46/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9140 - accuracy: 0.6449\n",
            "Epoch 46: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9149 - accuracy: 0.6454 - val_loss: 0.8849 - val_accuracy: 0.6444\n",
            "Epoch 47/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9139 - accuracy: 0.6446\n",
            "Epoch 47: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9142 - accuracy: 0.6444 - val_loss: 0.8929 - val_accuracy: 0.6428\n",
            "Epoch 48/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9056 - accuracy: 0.6485\n",
            "Epoch 48: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9060 - accuracy: 0.6486 - val_loss: 0.8861 - val_accuracy: 0.6451\n",
            "Epoch 49/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9049 - accuracy: 0.6494\n",
            "Epoch 49: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9050 - accuracy: 0.6493 - val_loss: 0.8990 - val_accuracy: 0.6356\n",
            "Epoch 50/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9036 - accuracy: 0.6527\n",
            "Epoch 50: saving model to l1norm_pruning_itr_7.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9028 - accuracy: 0.6532 - val_loss: 0.9068 - val_accuracy: 0.6321\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.9068 - accuracy: 0.6321\n",
            "Sparsity: 0.5179708331295442 | val loss: 0.9067739844322205 | val acc: 0.6320791840553284\n",
            "Epoch 1/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.3667 - accuracy: 0.4558\n",
            "Epoch 1: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.3665 - accuracy: 0.4562 - val_loss: 1.1342 - val_accuracy: 0.5457\n",
            "Epoch 2/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.1301 - accuracy: 0.5520\n",
            "Epoch 2: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1299 - accuracy: 0.5524 - val_loss: 1.0612 - val_accuracy: 0.5699\n",
            "Epoch 3/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0995 - accuracy: 0.5649\n",
            "Epoch 3: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0980 - accuracy: 0.5664 - val_loss: 1.0585 - val_accuracy: 0.5687\n",
            "Epoch 4/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0802 - accuracy: 0.5734\n",
            "Epoch 4: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0805 - accuracy: 0.5733 - val_loss: 1.0367 - val_accuracy: 0.5798\n",
            "Epoch 5/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0634 - accuracy: 0.5823\n",
            "Epoch 5: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0636 - accuracy: 0.5822 - val_loss: 1.0160 - val_accuracy: 0.5901\n",
            "Epoch 6/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0538 - accuracy: 0.5853\n",
            "Epoch 6: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0537 - accuracy: 0.5852 - val_loss: 1.0159 - val_accuracy: 0.5850\n",
            "Epoch 7/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 1.0420 - accuracy: 0.5936\n",
            "Epoch 7: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0424 - accuracy: 0.5935 - val_loss: 1.0010 - val_accuracy: 0.5929\n",
            "Epoch 8/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0321 - accuracy: 0.5969\n",
            "Epoch 8: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0331 - accuracy: 0.5967 - val_loss: 0.9833 - val_accuracy: 0.5992\n",
            "Epoch 9/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0258 - accuracy: 0.6017\n",
            "Epoch 9: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0259 - accuracy: 0.6016 - val_loss: 0.9764 - val_accuracy: 0.6067\n",
            "Epoch 10/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 1.0231 - accuracy: 0.6009\n",
            "Epoch 10: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0244 - accuracy: 0.5999 - val_loss: 0.9679 - val_accuracy: 0.6032\n",
            "Epoch 11/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0188 - accuracy: 0.6015\n",
            "Epoch 11: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0188 - accuracy: 0.6011 - val_loss: 0.9580 - val_accuracy: 0.6115\n",
            "Epoch 12/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0137 - accuracy: 0.6062\n",
            "Epoch 12: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0134 - accuracy: 0.6065 - val_loss: 0.9714 - val_accuracy: 0.6083\n",
            "Epoch 13/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0041 - accuracy: 0.6066\n",
            "Epoch 13: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0039 - accuracy: 0.6065 - val_loss: 0.9781 - val_accuracy: 0.6000\n",
            "Epoch 14/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9977 - accuracy: 0.6121\n",
            "Epoch 14: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9983 - accuracy: 0.6117 - val_loss: 0.9655 - val_accuracy: 0.6032\n",
            "Epoch 15/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9969 - accuracy: 0.6111\n",
            "Epoch 15: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9968 - accuracy: 0.6121 - val_loss: 0.9578 - val_accuracy: 0.6103\n",
            "Epoch 16/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9904 - accuracy: 0.6124\n",
            "Epoch 16: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9911 - accuracy: 0.6121 - val_loss: 0.9548 - val_accuracy: 0.6083\n",
            "Epoch 17/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9835 - accuracy: 0.6171\n",
            "Epoch 17: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9842 - accuracy: 0.6166 - val_loss: 0.9514 - val_accuracy: 0.6063\n",
            "Epoch 18/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9806 - accuracy: 0.6219\n",
            "Epoch 18: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9806 - accuracy: 0.6219 - val_loss: 0.9376 - val_accuracy: 0.6214\n",
            "Epoch 19/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9797 - accuracy: 0.6193\n",
            "Epoch 19: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9806 - accuracy: 0.6188 - val_loss: 0.9968 - val_accuracy: 0.5905\n",
            "Epoch 20/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9734 - accuracy: 0.6184\n",
            "Epoch 20: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9740 - accuracy: 0.6181 - val_loss: 0.9426 - val_accuracy: 0.6210\n",
            "Epoch 21/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9691 - accuracy: 0.6235\n",
            "Epoch 21: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9694 - accuracy: 0.6235 - val_loss: 0.9329 - val_accuracy: 0.6230\n",
            "Epoch 22/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9640 - accuracy: 0.6239\n",
            "Epoch 22: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9637 - accuracy: 0.6240 - val_loss: 0.9479 - val_accuracy: 0.6218\n",
            "Epoch 23/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9577 - accuracy: 0.6245\n",
            "Epoch 23: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9571 - accuracy: 0.6247 - val_loss: 0.9203 - val_accuracy: 0.6273\n",
            "Epoch 24/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9588 - accuracy: 0.6262\n",
            "Epoch 24: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9590 - accuracy: 0.6261 - val_loss: 0.9281 - val_accuracy: 0.6269\n",
            "Epoch 25/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9493 - accuracy: 0.6335\n",
            "Epoch 25: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9489 - accuracy: 0.6336 - val_loss: 0.9220 - val_accuracy: 0.6317\n",
            "Epoch 26/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9506 - accuracy: 0.6323\n",
            "Epoch 26: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9506 - accuracy: 0.6323 - val_loss: 0.9143 - val_accuracy: 0.6289\n",
            "Epoch 27/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9483 - accuracy: 0.6341\n",
            "Epoch 27: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9478 - accuracy: 0.6343 - val_loss: 0.9288 - val_accuracy: 0.6301\n",
            "Epoch 28/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9408 - accuracy: 0.6379\n",
            "Epoch 28: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9408 - accuracy: 0.6378 - val_loss: 0.9178 - val_accuracy: 0.6384\n",
            "Epoch 29/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9365 - accuracy: 0.6366\n",
            "Epoch 29: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9369 - accuracy: 0.6369 - val_loss: 0.9261 - val_accuracy: 0.6257\n",
            "Epoch 30/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9382 - accuracy: 0.6379\n",
            "Epoch 30: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9377 - accuracy: 0.6380 - val_loss: 0.8997 - val_accuracy: 0.6376\n",
            "Epoch 31/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9335 - accuracy: 0.6409\n",
            "Epoch 31: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9329 - accuracy: 0.6414 - val_loss: 0.9223 - val_accuracy: 0.6293\n",
            "Epoch 32/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9345 - accuracy: 0.6368\n",
            "Epoch 32: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9345 - accuracy: 0.6368 - val_loss: 0.9117 - val_accuracy: 0.6364\n",
            "Epoch 33/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9225 - accuracy: 0.6445\n",
            "Epoch 33: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9219 - accuracy: 0.6447 - val_loss: 0.9115 - val_accuracy: 0.6368\n",
            "Epoch 34/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9305 - accuracy: 0.6411\n",
            "Epoch 34: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9301 - accuracy: 0.6412 - val_loss: 0.9104 - val_accuracy: 0.6301\n",
            "Epoch 35/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9192 - accuracy: 0.6475\n",
            "Epoch 35: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9193 - accuracy: 0.6473 - val_loss: 0.8906 - val_accuracy: 0.6408\n",
            "Epoch 36/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9172 - accuracy: 0.6452\n",
            "Epoch 36: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9179 - accuracy: 0.6450 - val_loss: 0.8843 - val_accuracy: 0.6451\n",
            "Epoch 37/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9241 - accuracy: 0.6451\n",
            "Epoch 37: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9227 - accuracy: 0.6455 - val_loss: 0.8987 - val_accuracy: 0.6428\n",
            "Epoch 38/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9168 - accuracy: 0.6462\n",
            "Epoch 38: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9156 - accuracy: 0.6465 - val_loss: 0.8907 - val_accuracy: 0.6420\n",
            "Epoch 39/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9154 - accuracy: 0.6456\n",
            "Epoch 39: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9146 - accuracy: 0.6461 - val_loss: 0.8942 - val_accuracy: 0.6372\n",
            "Epoch 40/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9140 - accuracy: 0.6475\n",
            "Epoch 40: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9140 - accuracy: 0.6475 - val_loss: 0.9135 - val_accuracy: 0.6242\n",
            "Epoch 41/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9055 - accuracy: 0.6488\n",
            "Epoch 41: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9057 - accuracy: 0.6488 - val_loss: 0.8800 - val_accuracy: 0.6543\n",
            "Epoch 42/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9015 - accuracy: 0.6544\n",
            "Epoch 42: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9009 - accuracy: 0.6545 - val_loss: 0.9026 - val_accuracy: 0.6352\n",
            "Epoch 43/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9013 - accuracy: 0.6555\n",
            "Epoch 43: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9019 - accuracy: 0.6554 - val_loss: 0.8936 - val_accuracy: 0.6345\n",
            "Epoch 44/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.8991 - accuracy: 0.6545\n",
            "Epoch 44: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8993 - accuracy: 0.6546 - val_loss: 0.9062 - val_accuracy: 0.6317\n",
            "Epoch 45/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.8967 - accuracy: 0.6536\n",
            "Epoch 45: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8976 - accuracy: 0.6529 - val_loss: 0.9076 - val_accuracy: 0.6400\n",
            "Epoch 46/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.8968 - accuracy: 0.6544\n",
            "Epoch 46: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8978 - accuracy: 0.6538 - val_loss: 0.8778 - val_accuracy: 0.6444\n",
            "Epoch 47/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.8967 - accuracy: 0.6557\n",
            "Epoch 47: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8973 - accuracy: 0.6555 - val_loss: 0.8797 - val_accuracy: 0.6495\n",
            "Epoch 48/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.8959 - accuracy: 0.6558\n",
            "Epoch 48: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8948 - accuracy: 0.6559 - val_loss: 0.8732 - val_accuracy: 0.6491\n",
            "Epoch 49/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.8853 - accuracy: 0.6603\n",
            "Epoch 49: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8870 - accuracy: 0.6596 - val_loss: 0.8712 - val_accuracy: 0.6523\n",
            "Epoch 50/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.8895 - accuracy: 0.6566\n",
            "Epoch 50: saving model to l1norm_pruning_itr_8.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8895 - accuracy: 0.6566 - val_loss: 0.8866 - val_accuracy: 0.6459\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8866 - accuracy: 0.6459\n",
            "Sparsity: 0.524732136683234 | val loss: 0.8865513801574707 | val acc: 0.6459406018257141\n",
            "Epoch 1/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.3791 - accuracy: 0.4549\n",
            "Epoch 1: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.3749 - accuracy: 0.4562 - val_loss: 1.1007 - val_accuracy: 0.5509\n",
            "Epoch 2/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.1178 - accuracy: 0.5586\n",
            "Epoch 2: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.1171 - accuracy: 0.5588 - val_loss: 1.0457 - val_accuracy: 0.5842\n",
            "Epoch 3/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0789 - accuracy: 0.5772\n",
            "Epoch 3: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0789 - accuracy: 0.5778 - val_loss: 1.0310 - val_accuracy: 0.5905\n",
            "Epoch 4/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0660 - accuracy: 0.5826\n",
            "Epoch 4: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0668 - accuracy: 0.5818 - val_loss: 1.0235 - val_accuracy: 0.5952\n",
            "Epoch 5/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0545 - accuracy: 0.5853\n",
            "Epoch 5: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0542 - accuracy: 0.5856 - val_loss: 0.9908 - val_accuracy: 0.6040\n",
            "Epoch 6/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0400 - accuracy: 0.5938\n",
            "Epoch 6: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0399 - accuracy: 0.5938 - val_loss: 0.9795 - val_accuracy: 0.6063\n",
            "Epoch 7/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0313 - accuracy: 0.5932\n",
            "Epoch 7: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0300 - accuracy: 0.5941 - val_loss: 0.9888 - val_accuracy: 0.5964\n",
            "Epoch 8/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 1.0273 - accuracy: 0.5989\n",
            "Epoch 8: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0273 - accuracy: 0.5989 - val_loss: 0.9736 - val_accuracy: 0.6055\n",
            "Epoch 9/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0200 - accuracy: 0.6011\n",
            "Epoch 9: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0195 - accuracy: 0.6014 - val_loss: 0.9799 - val_accuracy: 0.6107\n",
            "Epoch 10/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0112 - accuracy: 0.6027\n",
            "Epoch 10: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0112 - accuracy: 0.6027 - val_loss: 0.9729 - val_accuracy: 0.6083\n",
            "Epoch 11/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 1.0102 - accuracy: 0.6051\n",
            "Epoch 11: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0105 - accuracy: 0.6052 - val_loss: 0.9522 - val_accuracy: 0.6143\n",
            "Epoch 12/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 1.0019 - accuracy: 0.6056\n",
            "Epoch 12: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0029 - accuracy: 0.6051 - val_loss: 0.9563 - val_accuracy: 0.6111\n",
            "Epoch 13/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 1.0001 - accuracy: 0.6109\n",
            "Epoch 13: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 1.0008 - accuracy: 0.6108 - val_loss: 0.9547 - val_accuracy: 0.6131\n",
            "Epoch 14/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9990 - accuracy: 0.6126\n",
            "Epoch 14: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9991 - accuracy: 0.6126 - val_loss: 0.9704 - val_accuracy: 0.6135\n",
            "Epoch 15/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 1.0001 - accuracy: 0.6099\n",
            "Epoch 15: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9991 - accuracy: 0.6107 - val_loss: 0.9425 - val_accuracy: 0.6261\n",
            "Epoch 16/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9891 - accuracy: 0.6170\n",
            "Epoch 16: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9876 - accuracy: 0.6172 - val_loss: 0.9394 - val_accuracy: 0.6202\n",
            "Epoch 17/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9811 - accuracy: 0.6198\n",
            "Epoch 17: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9811 - accuracy: 0.6198 - val_loss: 0.9290 - val_accuracy: 0.6234\n",
            "Epoch 18/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9752 - accuracy: 0.6192\n",
            "Epoch 18: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9756 - accuracy: 0.6190 - val_loss: 0.9227 - val_accuracy: 0.6289\n",
            "Epoch 19/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9792 - accuracy: 0.6189\n",
            "Epoch 19: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9788 - accuracy: 0.6187 - val_loss: 0.9346 - val_accuracy: 0.6281\n",
            "Epoch 20/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9715 - accuracy: 0.6228\n",
            "Epoch 20: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9722 - accuracy: 0.6223 - val_loss: 0.9261 - val_accuracy: 0.6273\n",
            "Epoch 21/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9667 - accuracy: 0.6251\n",
            "Epoch 21: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9670 - accuracy: 0.6251 - val_loss: 0.9308 - val_accuracy: 0.6265\n",
            "Epoch 22/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9637 - accuracy: 0.6258\n",
            "Epoch 22: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9638 - accuracy: 0.6256 - val_loss: 0.9268 - val_accuracy: 0.6257\n",
            "Epoch 23/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9610 - accuracy: 0.6267\n",
            "Epoch 23: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9610 - accuracy: 0.6268 - val_loss: 0.9284 - val_accuracy: 0.6329\n",
            "Epoch 24/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9561 - accuracy: 0.6311\n",
            "Epoch 24: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9567 - accuracy: 0.6308 - val_loss: 0.9250 - val_accuracy: 0.6273\n",
            "Epoch 25/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9552 - accuracy: 0.6303\n",
            "Epoch 25: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9551 - accuracy: 0.6300 - val_loss: 0.9065 - val_accuracy: 0.6372\n",
            "Epoch 26/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9434 - accuracy: 0.6332\n",
            "Epoch 26: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9435 - accuracy: 0.6330 - val_loss: 0.9241 - val_accuracy: 0.6293\n",
            "Epoch 27/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.9482 - accuracy: 0.6314\n",
            "Epoch 27: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9482 - accuracy: 0.6314 - val_loss: 0.9188 - val_accuracy: 0.6301\n",
            "Epoch 28/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9453 - accuracy: 0.6363\n",
            "Epoch 28: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9454 - accuracy: 0.6359 - val_loss: 0.8950 - val_accuracy: 0.6448\n",
            "Epoch 29/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9422 - accuracy: 0.6359\n",
            "Epoch 29: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9417 - accuracy: 0.6362 - val_loss: 0.9108 - val_accuracy: 0.6408\n",
            "Epoch 30/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9345 - accuracy: 0.6388\n",
            "Epoch 30: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9346 - accuracy: 0.6387 - val_loss: 0.9049 - val_accuracy: 0.6428\n",
            "Epoch 31/50\n",
            "172/176 [============================>.] - ETA: 0s - loss: 0.9278 - accuracy: 0.6412\n",
            "Epoch 31: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9280 - accuracy: 0.6418 - val_loss: 0.8872 - val_accuracy: 0.6432\n",
            "Epoch 32/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.9250 - accuracy: 0.6404\n",
            "Epoch 32: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9248 - accuracy: 0.6404 - val_loss: 0.8923 - val_accuracy: 0.6396\n",
            "Epoch 33/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9214 - accuracy: 0.6434\n",
            "Epoch 33: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9225 - accuracy: 0.6433 - val_loss: 0.8913 - val_accuracy: 0.6483\n",
            "Epoch 34/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9247 - accuracy: 0.6413\n",
            "Epoch 34: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9233 - accuracy: 0.6420 - val_loss: 0.8962 - val_accuracy: 0.6420\n",
            "Epoch 35/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9250 - accuracy: 0.6446\n",
            "Epoch 35: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9257 - accuracy: 0.6444 - val_loss: 0.8907 - val_accuracy: 0.6412\n",
            "Epoch 36/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.9186 - accuracy: 0.6502\n",
            "Epoch 36: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9179 - accuracy: 0.6499 - val_loss: 0.8807 - val_accuracy: 0.6471\n",
            "Epoch 37/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9107 - accuracy: 0.6484\n",
            "Epoch 37: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9121 - accuracy: 0.6472 - val_loss: 0.8942 - val_accuracy: 0.6412\n",
            "Epoch 38/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.9094 - accuracy: 0.6495\n",
            "Epoch 38: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9103 - accuracy: 0.6493 - val_loss: 0.9047 - val_accuracy: 0.6372\n",
            "Epoch 39/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9046 - accuracy: 0.6533\n",
            "Epoch 39: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9054 - accuracy: 0.6532 - val_loss: 0.8881 - val_accuracy: 0.6471\n",
            "Epoch 40/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.9071 - accuracy: 0.6475\n",
            "Epoch 40: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9074 - accuracy: 0.6475 - val_loss: 0.8962 - val_accuracy: 0.6471\n",
            "Epoch 41/50\n",
            "171/176 [============================>.] - ETA: 0s - loss: 0.8996 - accuracy: 0.6525\n",
            "Epoch 41: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.9003 - accuracy: 0.6523 - val_loss: 0.8649 - val_accuracy: 0.6582\n",
            "Epoch 42/50\n",
            "176/176 [==============================] - ETA: 0s - loss: 0.8954 - accuracy: 0.6529\n",
            "Epoch 42: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8954 - accuracy: 0.6529 - val_loss: 0.8867 - val_accuracy: 0.6408\n",
            "Epoch 43/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.9000 - accuracy: 0.6551\n",
            "Epoch 43: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8989 - accuracy: 0.6555 - val_loss: 0.8670 - val_accuracy: 0.6574\n",
            "Epoch 44/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.8969 - accuracy: 0.6525\n",
            "Epoch 44: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8958 - accuracy: 0.6529 - val_loss: 0.8733 - val_accuracy: 0.6554\n",
            "Epoch 45/50\n",
            "175/176 [============================>.] - ETA: 0s - loss: 0.8838 - accuracy: 0.6638\n",
            "Epoch 45: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8837 - accuracy: 0.6638 - val_loss: 0.8634 - val_accuracy: 0.6622\n",
            "Epoch 46/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.8858 - accuracy: 0.6566\n",
            "Epoch 46: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8855 - accuracy: 0.6568 - val_loss: 0.8638 - val_accuracy: 0.6582\n",
            "Epoch 47/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.8861 - accuracy: 0.6578\n",
            "Epoch 47: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8856 - accuracy: 0.6581 - val_loss: 0.8553 - val_accuracy: 0.6657\n",
            "Epoch 48/50\n",
            "174/176 [============================>.] - ETA: 0s - loss: 0.8829 - accuracy: 0.6611\n",
            "Epoch 48: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8835 - accuracy: 0.6609 - val_loss: 0.8705 - val_accuracy: 0.6550\n",
            "Epoch 49/50\n",
            "173/176 [============================>.] - ETA: 0s - loss: 0.8767 - accuracy: 0.6664\n",
            "Epoch 49: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8770 - accuracy: 0.6664 - val_loss: 0.8581 - val_accuracy: 0.6590\n",
            "Epoch 50/50\n",
            "170/176 [===========================>..] - ETA: 0s - loss: 0.8785 - accuracy: 0.6625\n",
            "Epoch 50: saving model to l1norm_pruning_itr_9.h5\n",
            "176/176 [==============================] - 2s 9ms/step - loss: 0.8775 - accuracy: 0.6634 - val_loss: 0.8798 - val_accuracy: 0.6570\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.8798 - accuracy: 0.6570\n",
            "Sparsity: 0.5382463111346476 | val loss: 0.8798452019691467 | val acc: 0.6570296883583069\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"../unpruned_val_acc_0.7493.h5\")\n",
        "unpruned_weights_std = calc_std(model.trainable_weights)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    pruned_weights = prune(model, factor=0.8, dense_thresh=3 * unpruned_weights_std)\n",
        "    model.set_weights(pruned_weights)\n",
        "\n",
        "    checkpoint_path = f\"l1norm_pruning_itr_{i}.h5\"\n",
        "\n",
        "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_path,\n",
        "        save_weights_only=True,\n",
        "        verbose=1,\n",
        "        monitor=\"val_accuracy\"\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        x=train_images, \n",
        "        y=train_labels,\n",
        "        epochs=50, \n",
        "        batch_size=128, \n",
        "        validation_data=(val_images, val_labels),\n",
        "        callbacks=[cp_callback]\n",
        "    )\n",
        "\n",
        "    val_loss, val_acc = model.evaluate(val_images, val_labels)\n",
        "    sparsity = measure_sparsity(model.trainable_weights)\n",
        "\n",
        "    print(f\"Sparsity: {sparsity} | val loss: {val_loss} | val acc: {val_acc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "5RCxrJojH9po",
        "outputId": "ae948f27-a4f9-4066-9b30-1c438b320918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 1s 12ms/step - loss: 1.0161 - accuracy: 0.5893\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.9844 - accuracy: 0.6063\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.9554 - accuracy: 0.6150\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.9018 - accuracy: 0.6388\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.9105 - accuracy: 0.6416\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.9089 - accuracy: 0.6440\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8819 - accuracy: 0.6463\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.9068 - accuracy: 0.6321\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8866 - accuracy: 0.6459\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8798 - accuracy: 0.6570\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"../unpruned_val_acc_0.7493.h5\")\n",
        "\n",
        "saved_res_files = sorted([file for file in os.listdir() if file.endswith(\".h5\")])\n",
        "\n",
        "sparsities = []\n",
        "val_accs = []\n",
        "\n",
        "for file in saved_res_files:\n",
        "  model.load_weights(file)\n",
        "  val_loss, val_acc = model.evaluate(val_images, val_labels)\n",
        "  sparsity = measure_sparsity(model.trainable_weights)\n",
        "  sparsities.append(sparsity)\n",
        "  val_accs.append(val_acc)\n",
        "                    \n",
        "itrs = list(range(len(saved_res_files)))\n",
        "\n",
        "COLOR_VAL_ACC = \"#69b3a2\"\n",
        "COLOR_SPARSITY = \"#3399e6\"\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "ax1.plot(itrs, val_accs, color=COLOR_VAL_ACC)\n",
        "ax2.plot(itrs, sparsities, color=COLOR_SPARSITY)\n",
        "\n",
        "\n",
        "fig.suptitle(\"Sparsity and Validation accuracy per itr\", fontsize=20)\n",
        "\n",
        "ax1.set_xlabel(\"Iteration\")\n",
        "\n",
        "ax1.set_ylabel(\"Validation Accuracy\", color=COLOR_VAL_ACC)\n",
        "ax2.set_ylabel(\"Sparsities\", color=COLOR_SPARSITY)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH-jyNEcGUjK",
        "outputId": "6fb74a79-8048-4ea1-b06e-c5259e686fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 0s 3ms/step - loss: 0.8866 - accuracy: 0.6459\n",
            "Post retraining val loss: 0.8865513801574707 | val acc: 0.6459406018257141 | sparsity: 0.524732136683234\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"../unpruned_val_acc_0.7493.h5\")\n",
        "model_path = \"l1norm_pruning_itr_8.h5\"\n",
        "model.load_weights(model_path)\n",
        "\n",
        "final_results = model.evaluate(val_images, val_labels)\n",
        "final_model_sparsity = measure_sparsity(model.trainable_weights)\n",
        "\n",
        "print(f\"Post retraining val loss: {final_results[0]} | val acc: {final_results[1]} | sparsity: {final_model_sparsity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLGUeh1oEAc5",
        "outputId": "47f9bf63-1457-4bf5-9c0f-d0fafb908b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8793 - accuracy: 0.7604\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 1.7902 - accuracy: 0.6063\n",
            "Factor: 0.1 | Sparsity: 0.010367107244832047 | val loss: 1.7902100086212158 | val acc: 0.6063366532325745\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 2.2447 - accuracy: 0.5061\n",
            "Factor: 0.1473684210526316 | Sparsity: 0.015817976061376242 | val loss: 2.2446749210357666 | val acc: 0.5061386227607727\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 3.6074 - accuracy: 0.4004\n",
            "Factor: 0.19473684210526315 | Sparsity: 0.020734214489664095 | val loss: 3.6073758602142334 | val acc: 0.40039604902267456\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 4.0369 - accuracy: 0.3667\n",
            "Factor: 0.24210526315789474 | Sparsity: 0.02618508330620829 | val loss: 4.0368523597717285 | val acc: 0.3667326867580414\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 3.5300 - accuracy: 0.2931\n",
            "Factor: 0.2894736842105263 | Sparsity: 0.03256185774783998 | val loss: 3.5300498008728027 | val acc: 0.2930693030357361\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 4.4967 - accuracy: 0.2780\n",
            "Factor: 0.33684210526315794 | Sparsity: 0.038012726564384175 | val loss: 4.496720790863037 | val acc: 0.27801981568336487\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 4.6731 - accuracy: 0.2749\n",
            "Factor: 0.38421052631578945 | Sparsity: 0.04292896499267202 | val loss: 4.673098087310791 | val acc: 0.2748514711856842\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 4.7547 - accuracy: 0.2741\n",
            "Factor: 0.43157894736842106 | Sparsity: 0.04837983380921622 | val loss: 4.754741191864014 | val acc: 0.2740594148635864\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 4.4577 - accuracy: 0.2705\n",
            "Factor: 0.4789473684210527 | Sparsity: 0.05329607223750407 | val loss: 4.457742691040039 | val acc: 0.27049505710601807\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 3.8190 - accuracy: 0.2384\n",
            "Factor: 0.5263157894736842 | Sparsity: 0.05874694105404826 | val loss: 3.8190152645111084 | val acc: 0.23841583728790283\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 2.7960 - accuracy: 0.2166\n",
            "Factor: 0.5736842105263158 | Sparsity: 0.06366317948233612 | val loss: 2.7959840297698975 | val acc: 0.2166336625814438\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 2.3600 - accuracy: 0.2269\n",
            "Factor: 0.6210526315789474 | Sparsity: 0.0691140482988803 | val loss: 2.359961986541748 | val acc: 0.22693069279193878\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 1.9399 - accuracy: 0.2127\n",
            "Factor: 0.6684210526315789 | Sparsity: 0.07403028672716816 | val loss: 1.9399482011795044 | val acc: 0.21267326176166534\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 1.9658 - accuracy: 0.1869\n",
            "Factor: 0.7157894736842105 | Sparsity: 0.07948115554371236 | val loss: 1.9658454656600952 | val acc: 0.18693068623542786\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 1.8122 - accuracy: 0.1980\n",
            "Factor: 0.7631578947368421 | Sparsity: 0.0843973939720002 | val loss: 1.8121600151062012 | val acc: 0.19801980257034302\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 2.1176 - accuracy: 0.1952\n",
            "Factor: 0.8105263157894737 | Sparsity: 0.08984826278854441 | val loss: 2.117607593536377 | val acc: 0.19524753093719482\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 1.9228 - accuracy: 0.2087\n",
            "Factor: 0.8578947368421053 | Sparsity: 0.09476450121683226 | val loss: 1.922793984413147 | val acc: 0.2087128758430481\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 1.8403 - accuracy: 0.2087\n",
            "Factor: 0.9052631578947369 | Sparsity: 0.10021537003337645 | val loss: 1.8403445482254028 | val acc: 0.2087128758430481\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 1.7898 - accuracy: 0.2087\n",
            "Factor: 0.9526315789473684 | Sparsity: 0.1051316084616643 | val loss: 1.7898290157318115 | val acc: 0.2087128758430481\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 1.9744 - accuracy: 0.1925\n",
            "Factor: 1.0 | Sparsity: 0.1105824772782085 | val loss: 1.9744346141815186 | val acc: 0.19247524440288544\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"../unpruned_val_acc_0.7493.h5\")\n",
        "unpruned_weights = deepcopy(model.trainable_weights)\n",
        "\n",
        "factors = np.linspace(0.1, 1, num=20)\n",
        "\n",
        "val_loss, val_acc = model.evaluate(val_images, val_labels)\n",
        "\n",
        "val_losses = [val_loss]\n",
        "val_accuracies = [val_acc]\n",
        "sparsities = [0]\n",
        "\n",
        "for factor in factors:\n",
        "    pruned_weights = prune(model, factor=factor, dense_thresh=None)\n",
        "    model.set_weights(pruned_weights)\n",
        "    \n",
        "    val_loss, val_acc = model.evaluate(val_images, val_labels)\n",
        "    sparsity = measure_sparsity(model.trainable_weights)\n",
        "    \n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "    sparsities.append(sparsity)\n",
        "    \n",
        "    print(f\"Factor: {factor} | Sparsity: {sparsity} | val loss: {val_loss} | val acc: {val_acc}\")\n",
        "    model.set_weights(unpruned_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "jkRMiP9H3Vdr",
        "outputId": "2caac9fe-dd4c-4c07-a1c8-88cdf631aeab"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots()\n",
        "axes.plot(sparsities, val_accuracies, marker=\"o\")\n",
        "axes.set_title(\"Pareto Frontier Validation Accuracy vs Sparsity\")\n",
        "axes.set_xlabel(\"Sparsity (* 100 for percentage)\")\n",
        "axes.set_ylabel(\"Validation Accuracy\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weV_m_ag3Vds"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "prune",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
